{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcion_2 = pd.read_parquet('user_item_model.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StringArray>\n",
      "[     'InstigatorAU', '76561198096849086',          'GamerFag',\n",
      "         'Bluegills',         'ripvision', '76561198088947777',\n",
      "         'epic_doom', '76561198049424642', '76561197970812298',\n",
      " '76561198069139035',\n",
      " ...\n",
      "      'shaman3soul3',           'waspish',             'cumme',\n",
      " '76561198015886143', '76561198072207162',           'Katidis',\n",
      " '76561198076217855',            '2ez2xl',       'matt1255555',\n",
      " 'LaLocaDeLosDulces']\n",
      "Length: 23157, dtype: string\n"
     ]
    }
   ],
   "source": [
    "# mostrar user_id unicos \n",
    "print(funcion_2['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userdata(User_id):\n",
    "    # Abrimos el archivo parquet en un dataframe\n",
    "    funcion_2 = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "    # Filtrar el dataframe 'games_reviews' por el 'User_id' dado\n",
    "    df_filtered = funcion_2[funcion_2['user_id'] == User_id]\n",
    "\n",
    "    # Verificar si el dataframe filtrado está vacío\n",
    "    if df_filtered.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": f\"El usuario {User_id} no existe.\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Calcular la cantidad de dinero gastado y redondearlo a dos decimales\n",
    "    total_spent = round(df_filtered['price'].sum(), 2)\n",
    "\n",
    "    # Calcular el porcentaje de recomendación\n",
    "    total_reviews = df_filtered['recommend'].count()\n",
    "    recommended_reviews = df_filtered[df_filtered['recommend'] == True]['recommend'].count()\n",
    "    recommendation_percentage = (recommended_reviews / total_reviews) * 100 if total_reviews > 0 else 0\n",
    "\n",
    "    # Calcular la cantidad de items\n",
    "    total_items = df_filtered['item_name'].nunique()\n",
    "\n",
    "    # Crear el diccionario de resultados\n",
    "    dict_userdata = {\n",
    "        \"Usuario\": User_id,\n",
    "        \"Dinero gastado\": f\"{total_spent} USD\",\n",
    "        \"% de recomendación\": f\"{recommendation_percentage}%\",\n",
    "        \"cantidad de artículos\": total_items\n",
    "    }\n",
    "\n",
    "    return dict_userdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Usuario': '76561198096849086',\n",
       " 'Dinero gastado': '229.88 USD',\n",
       " '% de recomendación': '100.0%',\n",
       " 'cantidad de artículos': 7}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llamando a la función userdata con el argumento '76561197960265729'\n",
    "userdata('76561198096849086')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "codigo modificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN 2 - CANTIDAD DE DINERO GASTADO POR USUARIO\n",
    "def user_data(user_id):\n",
    "    # Abrimos el archivo parquet en un dataframe\n",
    "    funcion_2 = pd.read_parquet('games.parquet')\n",
    "\n",
    "    # Filtrar el dataframe 'games_reviews' por el 'User_id' dado\n",
    "    df_filtered = funcion_2[funcion_2['user_id'] == user_id]\n",
    "\n",
    "    # Verificar si el dataframe filtrado está vacío\n",
    "    if df_filtered.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": f\"El usuario {user_id} no existe.\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Calcular la cantidad de dinero gastado y redondearlo a un entero\n",
    "    total_spent = int(df_filtered['price'].sum())\n",
    "\n",
    "    # Calcular el porcentaje de recomendación\n",
    "    total_reviews = df_filtered['recommend'].count()\n",
    "    recommended_reviews = df_filtered[df_filtered['recommend'] == True]['recommend'].count()\n",
    "    recommendation_percentage = int((recommended_reviews / total_reviews) * 100) if total_reviews > 0 else 0\n",
    "\n",
    "    # Calcular la cantidad de items\n",
    "    total_items = df_filtered['item_name'].nunique()\n",
    "\n",
    "    # Crear el diccionario de resultados\n",
    "    dict_userdata = {\n",
    "        \"Usuario\": user_id,\n",
    "        \"Dinero gastado\": f\"{total_spent} USD\",\n",
    "        \"% de recomendación\": f\"{recommendation_percentage}%\",\n",
    "        \"cantidad de artículos\": total_items\n",
    "    }\n",
    "\n",
    "    return dict_userdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'user_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\57301\\Desktop\\Copias_PI01-DATA19\\FastAPI_test\\FastAPI_testing\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'user_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# llamando a la función userdata con el argumento '76561197960265729'\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43muser_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m76561198096849086\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[44], line 7\u001b[0m, in \u001b[0;36muser_data\u001b[1;34m(user_id)\u001b[0m\n\u001b[0;32m      4\u001b[0m funcion_2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgames.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Filtrar el dataframe 'games_reviews' por el 'User_id' dado\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df_filtered \u001b[38;5;241m=\u001b[39m funcion_2[\u001b[43mfuncion_2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m user_id]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Verificar si el dataframe filtrado está vacío\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df_filtered\u001b[38;5;241m.\u001b[39mempty:\n",
      "File \u001b[1;32mc:\\Users\\57301\\Desktop\\Copias_PI01-DATA19\\FastAPI_test\\FastAPI_testing\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\57301\\Desktop\\Copias_PI01-DATA19\\FastAPI_test\\FastAPI_testing\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3807\u001b[0m     ):\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'user_id'"
     ]
    }
   ],
   "source": [
    "# llamando a la función userdata con el argumento '76561197960265729'\n",
    "user_data('76561198096849086')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "codigo de antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN 2 - CANTIDAD DE DINERO GASTADO POR USUARIO\n",
    "def user_data(user_id):\n",
    "    # Abrimos el archivo parquet en un dataframe\n",
    "    funcion_2 = pd.read_parquet('games_reviews_funcion_2.parquet')\n",
    "\n",
    "    # Filtrar el dataframe 'games_reviews' por el 'User_id' dado\n",
    "    df_filtered = funcion_2[funcion_2['user_id'] == user_id]\n",
    "\n",
    "    # Verificar si el dataframe filtrado está vacío\n",
    "    if df_filtered.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": f\"El usuario {user_id} no existe.\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Calcular la cantidad de dinero gastado y redondearlo a dos decimales\n",
    "    total_spent = round(df_filtered['price'].sum(), 2)\n",
    "\n",
    "    # Calcular el porcentaje de recomendación\n",
    "    total_reviews = df_filtered['recommend'].count()\n",
    "    recommended_reviews = df_filtered[df_filtered['recommend'] == True]['recommend'].count()\n",
    "    recommendation_percentage = (recommended_reviews / total_reviews) * 100 if total_reviews > 0 else 0\n",
    "\n",
    "    # Calcular la cantidad de items\n",
    "    total_items = df_filtered['item_name'].nunique()\n",
    "\n",
    "    # Crear el diccionario de resultados\n",
    "    dict_userdata = {\n",
    "        \"Usuario\": user_id,\n",
    "        \"Dinero gastado\": f\"{total_spent} USD\",\n",
    "        \"% de recomendación\": f\"{recommendation_percentage}%\",\n",
    "        \"cantidad de artículos\": total_items\n",
    "    }\n",
    "\n",
    "    return dict_userdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Usuario': '76561198096849086',\n",
       " 'Dinero gastado': '229.88 USD',\n",
       " '% de recomendación': '100.0%',\n",
       " 'cantidad de artículos': 7}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llamando a la función userdata con el argumento '76561197960265729'\n",
    "userdata('76561198096849086')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN 2 - CANTIDAD DE DINERO GASTADO POR USUARIO\n",
    "def user_data(user_id):\n",
    "    # Abrimos el archivo parquet en un dataframe\n",
    "    funcion_2 = pd.read_parquet('games_reviews_funcion_2.parquet')\n",
    "\n",
    "    # Filtrar el dataframe 'games_reviews' por el 'User_id' dado\n",
    "    df_filtered = funcion_2[funcion_2['user_id'] == user_id]\n",
    "\n",
    "    # Verificar si el dataframe filtrado está vacío\n",
    "    if df_filtered.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": f\"El usuario {user_id} no existe.\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Calcular la cantidad de dinero gastado y redondearlo a un entero\n",
    "    total_spent = int(df_filtered['price'].sum())\n",
    "\n",
    "    # Calcular el porcentaje de recomendación\n",
    "    total_reviews = df_filtered['recommend'].count()\n",
    "    recommended_reviews = df_filtered[df_filtered['recommend'] == True]['recommend'].count()\n",
    "    recommendation_percentage = int((recommended_reviews / total_reviews) * 100) if total_reviews > 0 else 0\n",
    "\n",
    "    # Calcular la cantidad de items\n",
    "    total_items = df_filtered['item_name'].nunique()\n",
    "\n",
    "    # Crear el diccionario de resultados\n",
    "    dict_userdata = {\n",
    "        \"Usuario\": user_id,\n",
    "        \"Dinero gastado\": f\"{total_spent} USD\",\n",
    "        \"% de recomendación\": f\"{recommendation_percentage}%\",\n",
    "        \"cantidad de artículos\": total_items\n",
    "    }\n",
    "\n",
    "    return dict_userdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Usuario': '76561198096849086',\n",
       " 'Dinero gastado': '229.88 USD',\n",
       " '% de recomendación': '100.0%',\n",
       " 'cantidad de artículos': 7}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llamando a la función userdata con el argumento '76561197960265729'\n",
    "userdata('76561198096849086')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN 1 - DESARROLLADORES CON JUEGOS GRATUITOS (que aparezca el otro item de contenido usado)\n",
    "def developer(desarrollador):\n",
    "    # Abrimos el archivo parquet en un dataframe\n",
    "    funcion_1=pd.read_parquet(\"games.parquet\")\n",
    "    # Filtrar el dataframe por el desarrollador dado\n",
    "    df_dev = funcion_1[funcion_1['developer'] == desarrollador]\n",
    "\n",
    "    # Si el dataframe está vacío, lanzar una excepción\n",
    "    if df_dev.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El desarrollador no existe\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    # Agrupar por año y contar el número total de juegos y el número de juegos gratuitos\n",
    "    juegos_por_año = df_dev.groupby('release_date').size()\n",
    "    juegos_gratis_por_año = df_dev[df_dev['price'] == 0.0].groupby('release_date').size()\n",
    "    \n",
    "    # Asegurarse de que juegos_gratis_por_año tenga la misma longitud que juegos_por_año\n",
    "    juegos_gratis_por_año = juegos_gratis_por_año.reindex(juegos_por_año.index, fill_value=0)\n",
    "    \n",
    "    # Calcular el porcentaje de juegos gratis y redondearlo al entero más cercano\n",
    "    porcentaje_gratis = ((juegos_gratis_por_año / juegos_por_año) * 100).round().astype(int)\n",
    "    \n",
    "    # Asignar nombres a las series\n",
    "    juegos_por_año.name = \"Cantidad de artículos\"\n",
    "    porcentaje_gratis.name = \"Porcentaje Gratis\"\n",
    "    \n",
    "    # Unir las dos series en un DataFrame\n",
    "    tabla = pd.concat([juegos_por_año, porcentaje_gratis], axis=1).reset_index()\n",
    "    tabla.columns = ['Año', 'Cantidad de artículos', 'Porcentaje Gratis']\n",
    "    \n",
    "    # Agregar el signo de porcentaje a 'Porcentaje Gratis'\n",
    "    tabla['Porcentaje Gratis'] = tabla['Porcentaje Gratis'].apply(lambda x: f\"{x}%\")\n",
    "    \n",
    "    # Convertir el DataFrame a un diccionario\n",
    "    dict_developer = tabla.to_dict(orient='records')\n",
    "    \n",
    "    return dict_developer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Año': 1998, 'Cantidad de artículos': 1, 'Porcentaje Gratis': '0%'},\n",
       " {'Año': 1999, 'Cantidad de artículos': 1, 'Porcentaje Gratis': '0%'},\n",
       " {'Año': 2000, 'Cantidad de artículos': 2, 'Porcentaje Gratis': '0%'},\n",
       " {'Año': 2001, 'Cantidad de artículos': 1, 'Porcentaje Gratis': '0%'},\n",
       " {'Año': 2003, 'Cantidad de artículos': 1, 'Porcentaje Gratis': '0%'},\n",
       " {'Año': 2004, 'Cantidad de artículos': 5, 'Porcentaje Gratis': '0%'},\n",
       " {'Año': 2005, 'Cantidad de artículos': 1, 'Porcentaje Gratis': '0%'},\n",
       " {'Año': 2006, 'Cantidad de artículos': 2, 'Porcentaje Gratis': '0%'},\n",
       " {'Año': 2007, 'Cantidad de artículos': 4, 'Porcentaje Gratis': '50%'},\n",
       " {'Año': 2008, 'Cantidad de artículos': 1, 'Porcentaje Gratis': '0%'},\n",
       " {'Año': 2009, 'Cantidad de artículos': 1, 'Porcentaje Gratis': '0%'},\n",
       " {'Año': 2010, 'Cantidad de artículos': 2, 'Porcentaje Gratis': '50%'},\n",
       " {'Año': 2011, 'Cantidad de artículos': 2, 'Porcentaje Gratis': '0%'},\n",
       " {'Año': 2012, 'Cantidad de artículos': 3, 'Porcentaje Gratis': '0%'},\n",
       " {'Año': 2014, 'Cantidad de artículos': 9, 'Porcentaje Gratis': '0%'},\n",
       " {'Año': 2016, 'Cantidad de artículos': 1, 'Porcentaje Gratis': '100%'},\n",
       " {'Año': 2017, 'Cantidad de artículos': 3, 'Porcentaje Gratis': '0%'}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llamar a la función developer con el argumento 'Valve'\n",
    "developer('Valve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN 3 - Usuario que acumula horas más jugadas para el genero dado\n",
    "def User_For_Genre(genero):\n",
    "\n",
    "    # Abrimos el archivo parquet en un dataframe\n",
    "    funcion_3 = pd.read_parquet('games_items.parquet')\n",
    "\n",
    "    # Filtrar el DataFrame por el género dado\n",
    "    df_genre = funcion_3[funcion_3['genres'] == genero]\n",
    "\n",
    "    # si el dataframe esta vacio, lanzar una excepcion \n",
    "    if df_genre.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El género no existe\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    # Obtener el usuario con más horas jugadas\n",
    "    user_most_played_id = df_genre.groupby('user_id')['playtime_forever'].sum().idxmax()\n",
    "\n",
    "    # Obtener la acumulación de horas jugadas por año de lanzamiento\n",
    "    hours_per_year = df_genre.groupby('release_date')['playtime_forever'].sum().astype(int).reset_index()\n",
    "    hours_per_year.columns = ['Año', 'Horas']\n",
    "\n",
    "    # Cambiar el valor del año a 'desconocido' cuando es igual a 0\n",
    "    hours_per_year['Año'] = hours_per_year['Año'].apply(lambda x: 'desconocido' if x == 0 else x)\n",
    "\n",
    "    # Crear el diccionario de resultados\n",
    "    hours_per_year = [{'Año': row['Año'], 'Horas': row['Horas']} for _, row in hours_per_year.iterrows()]\n",
    "\n",
    "    # Devolver los resultados en el formato especificado\n",
    "    return {\"Usuario con más horas jugadas para el género {}\".format(genero) : user_most_played_id, \"Horas jugadas\": hours_per_year}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Usuario con más horas jugadas para el género Design &amp; Illustration': 'BakaLunatic',\n",
       " 'Horas jugadas': [{'Año': 2007, 'Horas': 4},\n",
       "  {'Año': 2008, 'Horas': 1},\n",
       "  {'Año': 2012, 'Horas': 356},\n",
       "  {'Año': 2013, 'Horas': 359},\n",
       "  {'Año': 2014, 'Horas': 132},\n",
       "  {'Año': 2015, 'Horas': 651},\n",
       "  {'Año': 2016, 'Horas': 0},\n",
       "  {'Año': 2017, 'Horas': 0}]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llamando a la función User_For_Genre con el argumento 'Action'\n",
    "User_For_Genre('Design &amp; Illustration')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[                   'Action',                     'Indie',\n",
       "                    'Racing',                  'Strategy',\n",
       "                       'RPG',                'Simulation',\n",
       "                    'Casual',                 'Adventure',\n",
       "               'Desconocido',                    'Sports',\n",
       "     'Massively Multiplayer',                 'Utilities',\n",
       "  'Animation &amp; Modeling', 'Design &amp; Illustration',\n",
       "                 'Education',         'Software Training',\n",
       "            'Web Publishing',          'Video Production',\n",
       "          'Audio Production',             'Photo Editing']\n",
       "Length: 20, dtype: string"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostrar generos unicos\n",
    "g_i['genres'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrir el archivo games_items.parquet en un dataframe\n",
    "g_i= pd.read_parquet('games_items.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>release_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>playtime_forever</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>282010</td>\n",
       "      <td>Action</td>\n",
       "      <td>1997</td>\n",
       "      <td>76561198063896904</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282010</td>\n",
       "      <td>Action</td>\n",
       "      <td>1997</td>\n",
       "      <td>76561198091362266</td>\n",
       "      <td>0.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282010</td>\n",
       "      <td>Indie</td>\n",
       "      <td>1997</td>\n",
       "      <td>76561198063896904</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>282010</td>\n",
       "      <td>Indie</td>\n",
       "      <td>1997</td>\n",
       "      <td>76561198091362266</td>\n",
       "      <td>0.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>282010</td>\n",
       "      <td>Racing</td>\n",
       "      <td>1997</td>\n",
       "      <td>76561198063896904</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  genres  release_date            user_id  playtime_forever\n",
       "0   282010  Action          1997  76561198063896904          0.083333\n",
       "1   282010  Action          1997  76561198091362266          0.216667\n",
       "2   282010   Indie          1997  76561198063896904          0.083333\n",
       "3   282010   Indie          1997  76561198091362266          0.216667\n",
       "4   282010  Racing          1997  76561198063896904          0.083333"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_i.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105152 entries, 0 to 105151\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   item_id           105152 non-null  int32  \n",
      " 1   genres            105152 non-null  string \n",
      " 2   release_date      105152 non-null  int32  \n",
      " 3   user_id           105152 non-null  object \n",
      " 4   playtime_forever  105152 non-null  float64\n",
      "dtypes: float64(1), int32(2), object(1), string(1)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "g_i.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def load_data():\n",
    "    return pd.read_parquet('games_items.parquet')\n",
    "\n",
    "def filter_by_genre(df, genre):\n",
    "    return df[df['genres'] == genre]\n",
    "\n",
    "def get_user_most_played(df):\n",
    "    user_most_played_id = df.groupby('user_id')['playtime_forever'].sum().idxmax()\n",
    "    if isinstance(user_most_played_id, np.int64):\n",
    "        user_most_played_id = int(user_most_played_id)\n",
    "    return user_most_played_id\n",
    "\n",
    "def get_hours_per_year(df):\n",
    "    hours_per_year = df.groupby('release_date')['playtime_forever'].sum().astype(int).reset_index()\n",
    "    hours_per_year.columns = ['Año', 'Horas']\n",
    "    hours_per_year['Año'] = hours_per_year['Año'].apply(lambda x: 'desconocido' if x == 0 else x)\n",
    "    return [{'Año': row['Año'], 'Horas': int(row['Horas'])} for _, row in hours_per_year.iterrows()]\n",
    "\n",
    "def User_For_Genre(genero):\n",
    "    df = load_data()\n",
    "    df_genre = filter_by_genre(df, genero)\n",
    "\n",
    "    if df_genre.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El género no existe\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    user_most_played_id = get_user_most_played(df_genre)\n",
    "    hours_per_year = get_hours_per_year(df_genre)\n",
    "\n",
    "    return {\"Usuario con más horas jugadas para el género {}\".format(genero) : user_most_played_id, \"Horas jugadas\": hours_per_year}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Usuario con más horas jugadas para el género Design &amp; Illustration': 'BakaLunatic',\n",
       " 'Horas jugadas': [{'Año': 2007, 'Horas': 4},\n",
       "  {'Año': 2008, 'Horas': 1},\n",
       "  {'Año': 2012, 'Horas': 356},\n",
       "  {'Año': 2013, 'Horas': 359},\n",
       "  {'Año': 2014, 'Horas': 132},\n",
       "  {'Año': 2015, 'Horas': 651},\n",
       "  {'Año': 2016, 'Horas': 0},\n",
       "  {'Año': 2017, 'Horas': 0}]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llamar a la función User_For_Genre con el argumento 'Action'\n",
    "User_For_Genre('Design &amp; Illustration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrir un archivo parquet en un dataframe\n",
    "items_load = pd.read_parquet('item_item.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>recommend</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "      <th>item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Half-Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Half-Life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  recommend  sentiment_analysis             item_name\n",
       "0   282010          1                   1  Carmageddon Max Pack\n",
       "1   282010          1                   1  Carmageddon Max Pack\n",
       "2   282010          1                   1  Carmageddon Max Pack\n",
       "3       70          1                   0             Half-Life\n",
       "4       70          1                   0             Half-Life"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121562 entries, 0 to 121561\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   item_id             121562 non-null  int32 \n",
      " 1   recommend           121562 non-null  int64 \n",
      " 2   sentiment_analysis  121562 non-null  int32 \n",
      " 3   item_name           121562 non-null  object\n",
      "dtypes: int32(2), int64(1), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "items_load.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([282010,     70,   2400, ...,     30,  13230,     80])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valores unicos de la columna 'item_id'\n",
    "items_load['item_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>recommend</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "      <th>item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  recommend  sentiment_analysis             item_name\n",
       "0   282010          1                   1  Carmageddon Max Pack\n",
       "1   282010          1                   1  Carmageddon Max Pack\n",
       "2   282010          1                   1  Carmageddon Max Pack"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# buscar este item_id en el dataframe 282010\n",
    "items_load[items_load['item_id'] == 282010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>item_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>price</th>\n",
       "      <th>item_id</th>\n",
       "      <th>developer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [genres, item_name, release_date, price, item_id, developer]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# abrir un archivo parquet en un dataframe\n",
    "games = pd.read_parquet('games.parquet')\n",
    "games.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>release_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>playtime_forever</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [item_id, genres, release_date, user_id, playtime_forever]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_items = pd.read_parquet('games_items.parquet')\n",
    "games_items.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>item_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>price</th>\n",
       "      <th>item_id</th>\n",
       "      <th>developer</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_url</th>\n",
       "      <th>recommend</th>\n",
       "      <th>year</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Action</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "      <td>1997</td>\n",
       "      <td>9.99</td>\n",
       "      <td>282010</td>\n",
       "      <td>Stainless Games Ltd</td>\n",
       "      <td>InstigatorAU</td>\n",
       "      <td>http://steamcommunity.com/id/InstigatorAU</td>\n",
       "      <td>True</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Indie</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "      <td>1997</td>\n",
       "      <td>9.99</td>\n",
       "      <td>282010</td>\n",
       "      <td>Stainless Games Ltd</td>\n",
       "      <td>InstigatorAU</td>\n",
       "      <td>http://steamcommunity.com/id/InstigatorAU</td>\n",
       "      <td>True</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Racing</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "      <td>1997</td>\n",
       "      <td>9.99</td>\n",
       "      <td>282010</td>\n",
       "      <td>Stainless Games Ltd</td>\n",
       "      <td>InstigatorAU</td>\n",
       "      <td>http://steamcommunity.com/id/InstigatorAU</td>\n",
       "      <td>True</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genres             item_name  release_date  price  item_id  \\\n",
       "0  Action  Carmageddon Max Pack          1997   9.99   282010   \n",
       "1   Indie  Carmageddon Max Pack          1997   9.99   282010   \n",
       "2  Racing  Carmageddon Max Pack          1997   9.99   282010   \n",
       "\n",
       "             developer       user_id  \\\n",
       "0  Stainless Games Ltd  InstigatorAU   \n",
       "1  Stainless Games Ltd  InstigatorAU   \n",
       "2  Stainless Games Ltd  InstigatorAU   \n",
       "\n",
       "                                    user_url  recommend  year  \\\n",
       "0  http://steamcommunity.com/id/InstigatorAU       True  2014   \n",
       "1  http://steamcommunity.com/id/InstigatorAU       True  2014   \n",
       "2  http://steamcommunity.com/id/InstigatorAU       True  2014   \n",
       "\n",
       "   sentiment_analysis  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_reviews = pd.read_parquet('games_reviews.parquet')\n",
    "games_reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              InstigatorAU\n",
       "1              InstigatorAU\n",
       "2              InstigatorAU\n",
       "3         76561198096849086\n",
       "4                  GamerFag\n",
       "                ...        \n",
       "121557    LaLocaDeLosDulces\n",
       "121558        bindisposerer\n",
       "121559    76561198071835052\n",
       "121560               lachwe\n",
       "121561    76561198015050660\n",
       "Name: user_id, Length: 121562, dtype: string"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostrar la columna user_id\n",
    "games_reviews['user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genres\n",
       "Action         8\n",
       "Adventure      5\n",
       "Desconocido    1\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ver los generos que un usuario mas juega\n",
    "games_reviews[ games_reviews['user_id'] == '76561198096849086' ]['genres'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion_usuario(user_id):\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "    # Si el dataframe está vacío, devolver un mensaje de error\n",
    "    if data.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El DataFrame está vacío\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Si el user_id no existe en el DataFrame, devolver un mensaje de error\n",
    "    if user_id not in data['user_id'].values:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El user_id proporcionado no existe\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Filtrar los juegos que el usuario ha jugado\n",
    "    user_games = data[data['user_id'] == user_id]\n",
    "\n",
    "    # Obtener los géneros que el usuario juega más a menudo\n",
    "    top_genres = user_games['genres'].value_counts().index.tolist()\n",
    "\n",
    "    # Filtrar los juegos que pertenecen a los géneros favoritos del usuario\n",
    "    recommended_games = data[data['genres'].isin(top_genres)]\n",
    "\n",
    "    # Excluir los juegos que el usuario ya ha jugado\n",
    "    recommended_games = recommended_games[~recommended_games['item_id'].isin(user_games['item_id'])]\n",
    "\n",
    "    # Ordenar los juegos por su calificación y seleccionar los 5 mejores\n",
    "    recommended_games = recommended_games.sort_values('rating', ascending=False).head(5)\n",
    "\n",
    "    return { \"Juegos recomendados para el usuario\": recommended_games['item_name'].tolist() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llamar al usuario recomendado con el argumento '76561198096849086'\n",
    "recomendacion_usuario('76561198096849086')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no tienes una columna de calificación en tu DataFrame, puedes modificar la función para recomendar juegos basándote en otros criterios. Por ejemplo, podrías recomendar los juegos más populares (es decir, los que han sido jugados por más usuarios) dentro de los géneros favoritos del usuario. Aquí te dejo un ejemplo de cómo podrías hacerlo:\n",
    "\n",
    "\n",
    "Este código devuelve los 5 juegos más populares (es decir, los que han sido jugados por más usuarios) que pertenecen a los géneros que el usuario ha jugado más a menudo y que el usuario aún no ha jugado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion_usuario(user_id):\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "    # Si el dataframe está vacío, devolver un mensaje de error\n",
    "    if data.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El DataFrame está vacío\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Si el user_id no existe en el DataFrame, devolver un mensaje de error\n",
    "    if user_id not in data['user_id'].values:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El user_id proporcionado no existe\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Filtrar los juegos que el usuario ha jugado\n",
    "    user_games = data[data['user_id'] == user_id]\n",
    "\n",
    "    # Obtener los géneros que el usuario juega más a menudo\n",
    "    top_genres = user_games['genres'].value_counts().index.tolist()\n",
    "\n",
    "    # Filtrar los juegos que pertenecen a los géneros favoritos del usuario\n",
    "    recommended_games = data[data['genres'].isin(top_genres)]\n",
    "\n",
    "    # Excluir los juegos que el usuario ya ha jugado\n",
    "    recommended_games = recommended_games[~recommended_games['item_id'].isin(user_games['item_id'])]\n",
    "\n",
    "    # Calcular la popularidad de cada juego (número de usuarios que lo han jugado)\n",
    "    game_popularity = recommended_games['item_id'].value_counts()\n",
    "\n",
    "    # Obtener los 5 juegos más populares\n",
    "    top_games = game_popularity.head(5).index.tolist()\n",
    "\n",
    "    # Crear un diccionario con los ids y los nombres de los juegos\n",
    "    recommended_games = {game_id: data[data['item_id'] == game_id]['item_name'].iloc[0] for game_id in top_games}\n",
    "\n",
    "    return { f\"Juegos recomendados para el usuario {user_id}\": recommended_games }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Juegos recomendados para el usuario LaLocaDeLosDulces': {440: 'Team Fortress 2',\n",
       "  730: 'Counter-Strike: Global Offensive',\n",
       "  304930: 'Unturned',\n",
       "  252490: 'Rust',\n",
       "  221100: 'DayZ'}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llamar al usuario recomendado con el argumento '76561198096849086'\n",
    "recomendacion_usuario('LaLocaDeLosDulces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Juegos recomendados para el usuario': {440: 'Team Fortress 2',\n",
       "  730: 'Counter-Strike: Global Offensive',\n",
       "  304930: 'Unturned',\n",
       "  252490: 'Rust',\n",
       "  221100: 'DayZ'}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llamar al usuario recomendado con el argumento '76561198096849086'\n",
    "recomendacion_usuario('LaLocaDeLosDulces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion_usuario(user_id):\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "    # Si el dataframe está vacío, devolver un mensaje de error\n",
    "    if data.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El DataFrame está vacío\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Si el user_id no existe en el DataFrame, devolver un mensaje de error\n",
    "    if user_id not in data['user_id'].values:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El user_id proporcionado no existe\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Filtrar los juegos que el usuario ha jugado y recomendado\n",
    "    user_games = data[(data['user_id'] == user_id) & (data['recommend'] == True) & (data['sentiment_analysis'] == 2)]\n",
    "\n",
    "    # Obtener los géneros que el usuario juega más a menudo\n",
    "    top_genres = user_games['genres'].value_counts().index.tolist()\n",
    "\n",
    "    # Filtrar los juegos que pertenecen a los géneros favoritos del usuario\n",
    "    recommended_games = data[data['genres'].isin(top_genres)]\n",
    "\n",
    "    # Excluir los juegos que el usuario ya ha jugado\n",
    "    recommended_games = recommended_games[~recommended_games['item_id'].isin(user_games['item_id'])]\n",
    "\n",
    "    # Calcular la popularidad de cada juego (número de usuarios que lo han jugado)\n",
    "    game_popularity = recommended_games['item_id'].value_counts()\n",
    "\n",
    "    # Obtener los 5 juegos más populares\n",
    "    top_games = game_popularity.head(5).index.tolist()\n",
    "\n",
    "    # Crear un diccionario con los ids y los nombres de los juegos\n",
    "    recommended_games = {game_id: data[data['item_id'] == game_id]['item_name'].iloc[0] for game_id in top_games}\n",
    "\n",
    "    return { \"Juegos recomendados para el usuario\": recommended_games }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Juegos recomendados para el usuario': {}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llamar al usuario recomendado con el argumento '76561198096849086'\n",
    "recomendacion_usuario('76561198096849086')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion_usuario(user_id):\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "    # Si el dataframe está vacío, devolver un mensaje de error\n",
    "    if data.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El DataFrame está vacío\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Si el user_id no existe en el DataFrame, devolver un mensaje de error\n",
    "    if user_id not in data['user_id'].values:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El user_id proporcionado no existe\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Filtrar los juegos que el usuario ha jugado\n",
    "    user_games = data[data['user_id'] == user_id]\n",
    "\n",
    "    # Excluir los juegos que el usuario ya ha jugado\n",
    "    recommended_games = data[~data['item_id'].isin(user_games['item_id'])]\n",
    "\n",
    "    # Calcular la popularidad de cada juego (número de usuarios que lo han jugado)\n",
    "    game_popularity = recommended_games['item_id'].value_counts()\n",
    "\n",
    "    # Obtener los 5 juegos más populares\n",
    "    top_games = game_popularity.head(5).index.tolist()\n",
    "\n",
    "    # Crear un diccionario con los ids y los nombres de los juegos\n",
    "    recommended_games = {game_id: data[data['item_id'] == game_id]['item_name'].iloc[0] for game_id in top_games}\n",
    "\n",
    "    return { \"Juegos recomendados para el usuario\": recommended_games }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Juegos recomendados para el usuario': {304930: 'Unturned',\n",
       "  252490: 'Rust',\n",
       "  730: 'Counter-Strike: Global Offensive',\n",
       "  4000: \"Garry's Mod\",\n",
       "  221100: 'DayZ'}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llamar al usuario recomendado con el argumento '76561198096849086'\n",
    "recomendacion_usuario('76561198096849086')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para un sistema de recomendación basado en la similitud de coseno, podrías calcular la similitud entre los vectores de características de los juegos. Las características podrían incluir el género del juego, si el juego fue recomendado por el usuario y el análisis de sentimiento de los comentarios del usuario. Luego, podrías recomendar los juegos que son más similares a los juegos que el usuario ha jugado y recomendado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def recomendacion_usuario(user_id):\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "    # Crear una matriz de características\n",
    "    features = data[['genres', 'recommend', 'sentiment_analysis']]\n",
    "    encoder = OneHotEncoder().fit(features)\n",
    "    feature_matrix = encoder.transform(features).toarray()\n",
    "\n",
    "    # Calcular la similitud de coseno entre cada par de juegos\n",
    "    similarity_matrix = cosine_similarity(feature_matrix)\n",
    "\n",
    "    # Obtener los juegos que el usuario ha jugado y recomendado\n",
    "    user_games = data[(data['user_id'] == user_id) & (data['recommend'] == True)]\n",
    "\n",
    "    # Para cada juego que el usuario ha jugado y recomendado, encontrar los juegos más similares\n",
    "    similar_games = []\n",
    "    for index, row in user_games.iterrows():\n",
    "        similar_game_indices = np.argsort(similarity_matrix[index])[::-1]\n",
    "        similar_games.extend(similar_game_indices)\n",
    "\n",
    "    # Excluir los juegos que el usuario ya ha jugado\n",
    "    similar_games = [game for game in similar_games if game not in user_games['item_id'].values]\n",
    "\n",
    "    # Obtener los 5 juegos más similares\n",
    "    top_games = similar_games[:5]\n",
    "\n",
    "    # Crear un diccionario con los ids y los nombres de los juegos\n",
    "    recommended_games = {game_id: data[data['item_id'] == game_id]['item_name'].iloc[0] for game_id in top_games}\n",
    "\n",
    "    return { f\"Juegos recomendados para el usuario {user_id}\": recommended_games }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 110. GiB for an array with shape (121562, 121562) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# llamar al usuario recomendado con el argumento '76561198096849086'\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mrecomendacion_usuario\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m76561198096849086\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[51], line 14\u001b[0m, in \u001b[0;36mrecomendacion_usuario\u001b[1;34m(user_id)\u001b[0m\n\u001b[0;32m     11\u001b[0m feature_matrix \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mtransform(features)\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Calcular la similitud de coseno entre cada par de juegos\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m similarity_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Obtener los juegos que el usuario ha jugado y recomendado\u001b[39;00m\n\u001b[0;32m     17\u001b[0m user_games \u001b[38;5;241m=\u001b[39m data[(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m user_id) \u001b[38;5;241m&\u001b[39m (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecommend\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)]\n",
      "File \u001b[1;32mc:\\Users\\57301\\Desktop\\Copias_PI01-DATA19\\FastAPI_test\\FastAPI_testing\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\57301\\Desktop\\Copias_PI01-DATA19\\FastAPI_test\\FastAPI_testing\\venv\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1665\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1662\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1663\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1665\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_normalized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[1;32mc:\\Users\\57301\\Desktop\\Copias_PI01-DATA19\\FastAPI_test\\FastAPI_testing\\venv\\Lib\\site-packages\\sklearn\\utils\\extmath.py:189\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    187\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    192\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    196\u001b[0m ):\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 110. GiB for an array with shape (121562, 121562) and data type float64"
     ]
    }
   ],
   "source": [
    "# llamar al usuario recomendado con el argumento '76561198096849086'\n",
    "recomendacion_usuario('76561198096849086')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def recomendacion_usuario(user_id):\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "    # Crear una matriz de características\n",
    "    features = data[['genres', 'recommend', 'sentiment_analysis']]\n",
    "    encoder = OneHotEncoder().fit(features)\n",
    "    feature_matrix = encoder.transform(features).toarray()\n",
    "\n",
    "    # Reducir la dimensionalidad de la matriz de características con PCA\n",
    "    pca = PCA(n_components=100)  # Ajusta este número según la cantidad de memoria disponible\n",
    "    reduced_feature_matrix = pca.fit_transform(feature_matrix)\n",
    "\n",
    "    # Calcular la similitud de coseno entre cada par de juegos\n",
    "    similarity_matrix = cosine_similarity(reduced_feature_matrix)\n",
    "\n",
    "    # Obtener los juegos que el usuario ha jugado y recomendado\n",
    "    user_games = data[(data['user_id'] == user_id) & (data['recommend'] == True)]\n",
    "\n",
    "    # Para cada juego que el usuario ha jugado y recomendado, encontrar los juegos más similares\n",
    "    similar_games = []\n",
    "    for index, row in user_games.iterrows():\n",
    "        similar_game_indices = np.argsort(similarity_matrix[index])[::-1]\n",
    "        similar_games.extend(similar_game_indices)\n",
    "\n",
    "    # Excluir los juegos que el usuario ya ha jugado\n",
    "    similar_games = [game for game in similar_games if game not in user_games['item_id'].values]\n",
    "\n",
    "    # Obtener los 5 juegos más similares\n",
    "    top_games = similar_games[:5]\n",
    "\n",
    "    # Crear un diccionario con los ids y los nombres de los juegos\n",
    "    recommended_games = {game_id: data[data['item_id'] == game_id]['item_name'].iloc[0] for game_id in top_games}\n",
    "\n",
    "    return { f\"Juegos recomendados para el usuario {user_id}\": recommended_games }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=100 must be between 0 and min(n_samples, n_features)=24 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# llamar al usuario recomendado con el argumento '76561198096849086'\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mrecomendacion_usuario\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m76561198096849086\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[53], line 16\u001b[0m, in \u001b[0;36mrecomendacion_usuario\u001b[1;34m(user_id)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Reducir la dimensionalidad de la matriz de características con PCA\u001b[39;00m\n\u001b[0;32m     15\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)  \u001b[38;5;66;03m# Ajusta este número según la cantidad de memoria disponible\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m reduced_feature_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Calcular la similitud de coseno entre cada par de juegos\u001b[39;00m\n\u001b[0;32m     19\u001b[0m similarity_matrix \u001b[38;5;241m=\u001b[39m cosine_similarity(reduced_feature_matrix)\n",
      "File \u001b[1;32mc:\\Users\\57301\\Desktop\\Copias_PI01-DATA19\\FastAPI_test\\FastAPI_testing\\venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:273\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 273\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    276\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    277\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    278\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    279\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\57301\\Desktop\\Copias_PI01-DATA19\\FastAPI_test\\FastAPI_testing\\venv\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\57301\\Desktop\\Copias_PI01-DATA19\\FastAPI_test\\FastAPI_testing\\venv\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:454\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    433\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \n\u001b[0;32m    435\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;124;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 454\u001b[0m     U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m     U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhiten:\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;66;03m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\57301\\Desktop\\Copias_PI01-DATA19\\FastAPI_test\\FastAPI_testing\\venv\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:514\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_truncated(X, n_components, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver)\n",
      "File \u001b[1;32mc:\\Users\\57301\\Desktop\\Copias_PI01-DATA19\\FastAPI_test\\FastAPI_testing\\venv\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:530\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[1;34m(self, X, n_components)\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    527\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is only supported if n_samples >= n_features\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m         )\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n_components \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_samples, n_features):\n\u001b[1;32m--> 530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    531\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m must be between 0 and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin(n_samples, n_features)=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd_solver=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_components, \u001b[38;5;28mmin\u001b[39m(n_samples, n_features))\n\u001b[0;32m    534\u001b[0m     )\n\u001b[0;32m    536\u001b[0m \u001b[38;5;66;03m# Center data\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_ \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmean(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: n_components=100 must be between 0 and min(n_samples, n_features)=24 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "# llamar al usuario recomendado con el argumento '76561198096849086'\n",
    "recomendacion_usuario('76561198096849086')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def calcular_similitud():\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "    # Crear una matriz de características\n",
    "    features = data[['genres', 'recommend', 'sentiment_analysis']]\n",
    "    encoder = OneHotEncoder().fit(features)\n",
    "    feature_matrix = encoder.transform(features).toarray()\n",
    "\n",
    "    # Calcular la similitud de coseno entre cada par de juegos\n",
    "    similarity_matrix = cosine_similarity(feature_matrix)\n",
    "\n",
    "    # Guardar la matriz de similitud en un archivo\n",
    "    with open('similarity_matrix.pkl', 'wb') as f:\n",
    "        pickle.dump(similarity_matrix, f)\n",
    "\n",
    "def recomendacion_usuario(user_id):\n",
    "    # Cargar la matriz de similitud de un archivo\n",
    "    with open('similarity_matrix.pkl', 'rb') as f:\n",
    "        similarity_matrix = pickle.load(f)\n",
    "\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "    # Obtener los juegos que el usuario ha jugado y recomendado\n",
    "    user_games = data[(data['user_id'] == user_id) & (data['recommend'] == True)]\n",
    "\n",
    "    # Para cada juego que el usuario ha jugado y recomendado, encontrar los juegos más similares\n",
    "    similar_games = []\n",
    "    for index, row in user_games.iterrows():\n",
    "        similar_game_indices = np.argsort(similarity_matrix[index])[::-1]\n",
    "        similar_games.extend(similar_game_indices)\n",
    "\n",
    "    # Excluir los juegos que el usuario ya ha jugado\n",
    "    similar_games = [game for game in similar_games if game not in user_games['item_id'].values]\n",
    "\n",
    "    # Obtener los 5 juegos más similares\n",
    "    top_games = similar_games[:5]\n",
    "\n",
    "    # Crear un diccionario con los ids y los nombres de los juegos\n",
    "    recommended_games = {game_id: data[data['item_id'] == game_id]['item_name'].iloc[0] for game_id in top_games}\n",
    "\n",
    "    return { \"Juegos recomendados para el usuario\": recommended_games } \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('games_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genres                121562\n",
       "item_name             121562\n",
       "release_date          121562\n",
       "price                 121562\n",
       "item_id               121562\n",
       "developer             121562\n",
       "user_id               121562\n",
       "user_url              121562\n",
       "recommend             121562\n",
       "year                  121562\n",
       "sentiment_analysis    121562\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_similitud():\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "    # Tomar una muestra de 1000 datos\n",
    "    data_sample = data.sample(n=1000)\n",
    "\n",
    "    # Crear una matriz de características\n",
    "    features = data_sample[['genres', 'recommend', 'sentiment_analysis']]\n",
    "    encoder = OneHotEncoder().fit(features)\n",
    "    feature_matrix = encoder.transform(features).toarray()\n",
    "\n",
    "    # Calcular la similitud de coseno entre cada par de juegos\n",
    "    similarity_matrix = cosine_similarity(feature_matrix)\n",
    "\n",
    "    # Guardar la matriz de similitud en un archivo\n",
    "    with open('similarity_matrix.pkl', 'wb') as f:\n",
    "        pickle.dump(similarity_matrix, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probando otras ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def calcular_similitud():\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "    # Tomar una muestra de 1000 datos\n",
    "    data_sample = data.sample(n=1000)\n",
    "\n",
    "    # Guardar la muestra de datos en un archivo\n",
    "    data_sample.to_parquet('games_reviews_muestra.parquet')\n",
    "\n",
    "    # Crear una matriz de características\n",
    "    features = data_sample[['genres', 'recommend', 'sentiment_analysis']]\n",
    "    encoder = OneHotEncoder().fit(features)\n",
    "    feature_matrix = encoder.transform(features).toarray()\n",
    "\n",
    "    # Calcular la similitud de coseno entre cada par de juegos\n",
    "    similarity_matrix = cosine_similarity(feature_matrix)\n",
    "\n",
    "    # Convertir la matriz de similitud en un DataFrame\n",
    "    similarity_df = pd.DataFrame(similarity_matrix)\n",
    "\n",
    "    # Guardar el DataFrame en un archivo pkl\n",
    "    similarity_df.to_pickle('similarity_matrix.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llamar a la funcion calcular_similitud\n",
    "calcular_similitud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_similitud():\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "    # eliminar las columnas release_date, price, developer, user_url, year\n",
    "    data = data.drop(columns=['release_date', 'price', 'developer', 'user_url', 'year'])\n",
    "\n",
    "    # Tomar una muestra de 1000 datos y reiniciar los índices\n",
    "    data_sample = data.sample(n=1000).reset_index(drop=True)\n",
    "\n",
    "    # Guardar la muestra de datos en un archivo\n",
    "    data_sample.to_parquet('games_reviews_muestra.parquet')\n",
    "\n",
    "    # Crear una matriz de características\n",
    "    features = data_sample[['genres', 'recommend', 'sentiment_analysis']]\n",
    "    encoder = OneHotEncoder().fit(features)\n",
    "    feature_matrix = encoder.transform(features).toarray()\n",
    "\n",
    "    # Calcular la similitud de coseno entre cada par de juegos\n",
    "    similarity_matrix = cosine_similarity(feature_matrix)\n",
    "\n",
    "    # Convertir la matriz de similitud en un DataFrame\n",
    "    similarity_df = pd.DataFrame(similarity_matrix)\n",
    "\n",
    "    # Guardar el DataFrame en un archivo pkl\n",
    "    similarity_df.to_pickle('similarity_matrix.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcular_similitud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion_usuario(user_id):\n",
    "    # Cargar la matriz de similitud de un archivo\n",
    "    similarity_matrix = pd.read_pickle('similarity_matrix.pkl')\n",
    "\n",
    "    # Abrir la muestra de datos de un archivo\n",
    "    data = pd.read_parquet('games_reviews_muestra.parquet')\n",
    "\n",
    "    # Obtener los juegos que el usuario ha jugado y recomendado\n",
    "    user_games = data[(data['user_id'] == user_id) & (data['recommend'] == True)].reset_index(drop=True)\n",
    "\n",
    "    # Para cada juego que el usuario ha jugado y recomendado, encontrar los juegos más similares\n",
    "    similar_games = []\n",
    "    for index, row in user_games.iterrows():\n",
    "        similar_game_indices = np.argsort(similarity_matrix[index])[::-1]\n",
    "        similar_games.extend(similar_game_indices)\n",
    "\n",
    "    # Excluir los juegos que el usuario ya ha jugado\n",
    "    similar_games = [game for game in similar_games if game not in user_games['item_id'].values]\n",
    "\n",
    "    # Obtener los 5 juegos más similares\n",
    "    top_games = similar_games[:5]\n",
    "\n",
    "    # Crear un diccionario con los ids y los nombres de los juegos\n",
    "    recommended_games = {game_id: data[data['item_id'] == game_id]['item_name'].iloc[0] for game_id in top_games}\n",
    "\n",
    "    return { \"Juegos recomendados para el usuario\": recommended_games }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llamar al usuario recomendado con el argumento '76561198096849086'\n",
    "recomendacion_usuario('LukasTrotacielos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrir el archivo pkl en un dataframe\n",
    "similarity_df_ver = pd.read_pickle('similarity_matrix.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5    6         7    \\\n",
       "0  1.000000  1.000000  1.000000  1.000000  0.666667  1.000000  0.0  0.666667   \n",
       "1  1.000000  1.000000  1.000000  1.000000  0.666667  1.000000  0.0  0.666667   \n",
       "2  1.000000  1.000000  1.000000  1.000000  0.666667  1.000000  0.0  0.666667   \n",
       "3  1.000000  1.000000  1.000000  1.000000  0.666667  1.000000  0.0  0.666667   \n",
       "4  0.666667  0.666667  0.666667  0.666667  1.000000  0.666667  0.0  0.666667   \n",
       "\n",
       "        8         9    ...       990       991       992       993       994  \\\n",
       "0  1.000000  0.666667  ...  1.000000  0.666667  0.333333  0.333333  0.666667   \n",
       "1  1.000000  0.666667  ...  1.000000  0.666667  0.333333  0.333333  0.666667   \n",
       "2  1.000000  0.666667  ...  1.000000  0.666667  0.333333  0.333333  0.666667   \n",
       "3  1.000000  0.666667  ...  1.000000  0.666667  0.333333  0.333333  0.666667   \n",
       "4  0.666667  0.666667  ...  0.666667  0.666667  0.333333  0.333333  0.666667   \n",
       "\n",
       "        995       996       997       998       999  \n",
       "0  0.666667  0.666667  0.666667  0.666667  0.333333  \n",
       "1  0.666667  0.666667  0.666667  0.666667  0.333333  \n",
       "2  0.666667  0.666667  0.666667  0.666667  0.333333  \n",
       "3  0.666667  0.666667  0.666667  0.666667  0.333333  \n",
       "4  1.000000  0.666667  0.666667  0.666667  0.333333  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_df_ver.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrir el archivo parquet en un dataframe\n",
    "games_deleted = pd.read_parquet('games_reviews_muestra.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en un nuevo dataframe llamado games_reviews_muestra seleccionar las siguientes columnas user_id, item_id, item_name, recommend\n",
    "games_deleted = games_deleted[['user_id', 'item_id', 'item_name', 'recommend']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>recommend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78669</th>\n",
       "      <td>76561198032373589</td>\n",
       "      <td>246420</td>\n",
       "      <td>Kingdom Rush</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67637</th>\n",
       "      <td>76561198063180532</td>\n",
       "      <td>346010</td>\n",
       "      <td>Besiege</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>LukasTrotacielos</td>\n",
       "      <td>4000</td>\n",
       "      <td>Garry's Mod</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>fsociety_00</td>\n",
       "      <td>4000</td>\n",
       "      <td>Garry's Mod</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85148</th>\n",
       "      <td>76561198072109766</td>\n",
       "      <td>252490</td>\n",
       "      <td>Rust</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id  item_id     item_name  recommend\n",
       "78669  76561198032373589   246420  Kingdom Rush       True\n",
       "67637  76561198063180532   346010       Besiege       True\n",
       "1421    LukasTrotacielos     4000   Garry's Mod       True\n",
       "576          fsociety_00     4000   Garry's Mod       True\n",
       "85148  76561198072109766   252490          Rust       True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_deleted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar el dataframe games_deleted en un archivo parquet llamado games_reviews_muestra\n",
    "games_deleted.to_parquet('games_reviews_muestra.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>item_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>price</th>\n",
       "      <th>item_id</th>\n",
       "      <th>developer</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_url</th>\n",
       "      <th>recommend</th>\n",
       "      <th>year</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78669</th>\n",
       "      <td>Indie</td>\n",
       "      <td>Kingdom Rush</td>\n",
       "      <td>2014</td>\n",
       "      <td>9.99</td>\n",
       "      <td>246420</td>\n",
       "      <td>Ironhide Game Studio</td>\n",
       "      <td>76561198032373589</td>\n",
       "      <td>http://steamcommunity.com/profiles/76561198032...</td>\n",
       "      <td>True</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67637</th>\n",
       "      <td>Indie</td>\n",
       "      <td>Besiege</td>\n",
       "      <td>2015</td>\n",
       "      <td>7.99</td>\n",
       "      <td>346010</td>\n",
       "      <td>Spiderling Studios</td>\n",
       "      <td>76561198063180532</td>\n",
       "      <td>http://steamcommunity.com/profiles/76561198063...</td>\n",
       "      <td>True</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>Indie</td>\n",
       "      <td>Garry's Mod</td>\n",
       "      <td>2006</td>\n",
       "      <td>9.99</td>\n",
       "      <td>4000</td>\n",
       "      <td>Facepunch Studios</td>\n",
       "      <td>LukasTrotacielos</td>\n",
       "      <td>http://steamcommunity.com/id/LukasTrotacielos</td>\n",
       "      <td>True</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>Indie</td>\n",
       "      <td>Garry's Mod</td>\n",
       "      <td>2006</td>\n",
       "      <td>9.99</td>\n",
       "      <td>4000</td>\n",
       "      <td>Facepunch Studios</td>\n",
       "      <td>fsociety_00</td>\n",
       "      <td>http://steamcommunity.com/id/fsociety_00</td>\n",
       "      <td>True</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85148</th>\n",
       "      <td>RPG</td>\n",
       "      <td>Rust</td>\n",
       "      <td>2013</td>\n",
       "      <td>19.99</td>\n",
       "      <td>252490</td>\n",
       "      <td>Facepunch Studios</td>\n",
       "      <td>76561198072109766</td>\n",
       "      <td>http://steamcommunity.com/profiles/76561198072...</td>\n",
       "      <td>True</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      genres     item_name  release_date  price  item_id  \\\n",
       "78669  Indie  Kingdom Rush          2014   9.99   246420   \n",
       "67637  Indie       Besiege          2015   7.99   346010   \n",
       "1421   Indie   Garry's Mod          2006   9.99     4000   \n",
       "576    Indie   Garry's Mod          2006   9.99     4000   \n",
       "85148    RPG          Rust          2013  19.99   252490   \n",
       "\n",
       "                  developer            user_id  \\\n",
       "78669  Ironhide Game Studio  76561198032373589   \n",
       "67637    Spiderling Studios  76561198063180532   \n",
       "1421      Facepunch Studios   LukasTrotacielos   \n",
       "576       Facepunch Studios        fsociety_00   \n",
       "85148     Facepunch Studios  76561198072109766   \n",
       "\n",
       "                                                user_url  recommend  year  \\\n",
       "78669  http://steamcommunity.com/profiles/76561198032...       True  2014   \n",
       "67637  http://steamcommunity.com/profiles/76561198063...       True  2015   \n",
       "1421       http://steamcommunity.com/id/LukasTrotacielos       True  2014   \n",
       "576             http://steamcommunity.com/id/fsociety_00       True  2014   \n",
       "85148  http://steamcommunity.com/profiles/76561198072...       True  2014   \n",
       "\n",
       "       sentiment_analysis  \n",
       "78669                   2  \n",
       "67637                   2  \n",
       "1421                    2  \n",
       "576                     2  \n",
       "85148                   2  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_deleted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD probando otros enfoques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'hours'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\57301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\57301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\57301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'hours'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Crear la columna 'rating'\u001b[39;00m\n\u001b[0;32m     13\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 14\u001b[0m data\u001b[38;5;241m.\u001b[39mloc[(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhours\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m&\u001b[39m (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecommend\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     15\u001b[0m data\u001b[38;5;241m.\u001b[39mloc[(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhours\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m&\u001b[39m (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecommend\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m     16\u001b[0m data\u001b[38;5;241m.\u001b[39mloc[(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhours\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecommend\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\57301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\57301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'hours'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split, GridSearchCV\n",
    "import pickle\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_parquet('games_reviews_muestra.parquet')\n",
    "\n",
    "# Reemplazar los valores de la columna 'recommend'\n",
    "data['recommend'] = data['recommend'].replace({True: 1, False: 0})\n",
    "\n",
    "# Crear la columna 'rating'\n",
    "data['rating'] = 0\n",
    "data.loc[(data['hours'] == 2) & (data['recommend'] == 1), 'rating'] = 5\n",
    "data.loc[(data['hours'] == 2) & (data['recommend'] == 0), 'rating'] = 4\n",
    "data.loc[(data['hours'] == 1) & (data['recommend'] == 1), 'rating'] = 3\n",
    "data.loc[(data['hours'] == 1) & (data['recommend'] == 0), 'rating'] = 2\n",
    "data.loc[(data['hours'] == 0) & (data['recommend'] == 1), 'rating'] = 1\n",
    "\n",
    "# Guardar el DataFrame en un nuevo archivo .parquet\n",
    "data.to_parquet('user_item_model.parquet')\n",
    "\n",
    "# Cargar los datos del archivo .parquet\n",
    "new_df = pd.read_parquet('user_item_model.parquet')\n",
    "\n",
    "# Adaptar rating_scale a la escala de datos\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "\n",
    "# Cargar los datos en un objeto Dataset de Surprise\n",
    "data = Dataset.load_from_df(new_df[['user_id', 'item_name', 'rating']], reader)\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optimizar los hiperparámetros con GridSearchCV\n",
    "param_grid = {'n_factors': [5, 50, 100], 'n_epochs': [5, 10, 20], 'lr_all': [0.001, 0.002, 0.005], 'reg_all': [0.002, 0.02, 0.2]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=5, n_jobs=-1)\n",
    "gs.fit(data)\n",
    "\n",
    "# Entrenar el modelo SVD con los hiperparámetros optimizados\n",
    "model = SVD(**gs.best_params['rmse'])\n",
    "model.fit(trainset)\n",
    "\n",
    "# Guardar el modelo en un archivo .pkl\n",
    "with open('user_item_model.pkl', 'wb') as archivo:\n",
    "    pickle.dump(model, archivo)\n",
    "\n",
    "# Cargar el modelo del archivo .pkl\n",
    "with open('user_item_model.pkl', 'rb') as archivo:\n",
    "    modelo = pickle.load(archivo)\n",
    "\n",
    "# Definir la función recomendacion_usuario\n",
    "def recomendacion_usuario(id_usuario):\n",
    "    if id_usuario not in new_df['user_id'].unique():\n",
    "        return {'error': 'El usuario especificado no existe.'}\n",
    "\n",
    "    juegos_valorados = new_df[new_df['user_id'] == id_usuario]['item_name'].unique()\n",
    "    todos_los_juegos = new_df['item_name'].unique()\n",
    "    juegos_no_valorados = list(set(todos_los_juegos) - set(juegos_valorados))\n",
    "    predicciones = [modelo.predict(id_usuario, juego) for juego in juegos_no_valorados]\n",
    "    recomendaciones = sorted(predicciones, key=lambda x: x.est, reverse=True)[:5]\n",
    "    juegos_recomendados = [recomendacion.iid for recomendacion in recomendaciones]\n",
    "    recomendaciones_dict = {'Juego 1': juegos_recomendados[0], 'Juego 2': juegos_recomendados[1], 'Juego 3': juegos_recomendados[2], 'Juego 4': juegos_recomendados[3], 'Juego 5': juegos_recomendados[4]}\n",
    "    return recomendaciones_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrir un archivo parquet en un dataframe\n",
    "import pandas as pd\n",
    "modelode = pd.read_parquet('parquet/user_item_model.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "['76561198088228692', '76561198058892591', '76561198064710856',\n",
       " '76561198102514027', '76561198079589220',         'GamerEdge',\n",
       " '76561198087419337', '76561198101093216',        'QueenJesus',\n",
       "         'Deepadeep',\n",
       " ...\n",
       " '76561198060046037',    'NickiManaj2001',       'Andromnicus',\n",
       "   'anonymoosebrony',     'hihihello1234', '76561198022918599',\n",
       "       'originaldog',             'Vapas',        'darthdan97',\n",
       " '76561198062374715']\n",
       "Length: 963, dtype: string"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostrar todos los user_id unicos\n",
    "modelode['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split, GridSearchCV\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Definir la función recomendacion_usuario\n",
    "def recomendacion_usuario(user_id):\n",
    "    # Cargar el modelo del archivo .pkl\n",
    "    with open('user_item_model.pkl', 'rb') as archivo:\n",
    "        modelo = pickle.load(archivo)\n",
    "\n",
    "    if user_id not in new_df['user_id'].unique():\n",
    "        return {'error': 'El usuario especificado no existe.'}\n",
    "\n",
    "    juegos_valorados = new_df[new_df['user_id'] == user_id]['item_name'].unique()\n",
    "    todos_los_juegos = new_df['item_name'].unique()\n",
    "    juegos_no_valorados = list(set(todos_los_juegos) - set(juegos_valorados))\n",
    "    predicciones = [modelo.predict(user_id, juego) for juego in juegos_no_valorados]\n",
    "    recomendaciones = sorted(predicciones, key=lambda x: x.est, reverse=True)[:5]\n",
    "    juegos_recomendados = [recomendacion.iid for recomendacion in recomendaciones]\n",
    "    recomendaciones_dict = {'Juego 1': juegos_recomendados[0], 'Juego 2': juegos_recomendados[1], 'Juego 3': juegos_recomendados[2], 'Juego 4': juegos_recomendados[3], 'Juego 5': juegos_recomendados[4]}\n",
    "    return recomendaciones_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recomendacion_usuario('NickiManaj2001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split, GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "data = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "# Reemplazar los valores de la columna 'recommend'\n",
    "data['recommend'] = data['recommend'].replace({True: 1, False: 0})\n",
    "\n",
    "# Crear la columna 'rating'\n",
    "data['rating'] = 0\n",
    "data.loc[(data['sentiment_analysis'] == 2) & (data['recommend'] == 1), 'rating'] = 5\n",
    "data.loc[(data['sentiment_analysis'] == 2) & (data['recommend'] == 0), 'rating'] = 4\n",
    "data.loc[(data['sentiment_analysis'] == 1) & (data['recommend'] == 1), 'rating'] = 3\n",
    "data.loc[(data['sentiment_analysis'] == 1) & (data['recommend'] == 0), 'rating'] = 2\n",
    "data.loc[(data['sentiment_analysis'] == 0) & (data['recommend'] == 1), 'rating'] = 1\n",
    "\n",
    "# Guardar el DataFrame en un nuevo archivo .parquet\n",
    "data.to_parquet('user_item_model.parquet')\n",
    "\n",
    "# Cargar los datos del archivo .parquet\n",
    "new_df = pd.read_parquet('user_item_model.parquet')\n",
    "\n",
    "# Adaptar rating_scale a la escala de datos\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "\n",
    "# Cargar los datos en un objeto Dataset de Surprise\n",
    "data = Dataset.load_from_df(new_df[['user_id', 'item_name', 'rating']], reader)\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optimizar los hiperparámetros con GridSearchCV\n",
    "param_grid = {'n_factors': [5, 50, 100], 'n_epochs': [5, 10, 20], 'lr_all': [0.001, 0.002, 0.005], 'reg_all': [0.002, 0.02, 0.2]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=5, n_jobs=-1)\n",
    "gs.fit(data)\n",
    "\n",
    "# Entrenar el modelo SVD con los hiperparámetros optimizados\n",
    "model = SVD(**gs.best_params['rmse'])\n",
    "model.fit(trainset)\n",
    "\n",
    "# Guardar el modelo en un archivo csv\n",
    "model.to_csv('user_item_model.csv')\n",
    "\n",
    "# Guardar el modelo en un archivo .pkl\n",
    "with open('user_item_model.pkl', 'wb') as archivo:\n",
    "    pickle.dump(model, archivo)\n",
    "\n",
    "# Cargar el modelo del archivo .pkl\n",
    "with open('user_item_model.pkl', 'rb') as archivo:\n",
    "    modelo = pickle.load(archivo)\n",
    "\n",
    "# Definir la función recomendacion_usuario\n",
    "def recomendacion_usuario(user_id):\n",
    "    if user_id not in new_df['user_id'].unique():\n",
    "        return {'error': 'El usuario especificado no existe.'}\n",
    "\n",
    "    juegos_valorados = new_df[new_df['user_id'] == user_id]['item_name'].unique()\n",
    "    todos_los_juegos = new_df['item_name'].unique()\n",
    "    juegos_no_valorados = list(set(todos_los_juegos) - set(juegos_valorados))\n",
    "    predicciones = [modelo.predict(user_id, juego) for juego in juegos_no_valorados]\n",
    "    recomendaciones = sorted(predicciones, key=lambda x: x.est, reverse=True)[:5]\n",
    "    juegos_recomendados = [recomendacion.iid for recomendacion in recomendaciones]\n",
    "    recomendaciones_dict = {f\"Juegos recomendados para el usuario {user_id}: \" 'Juego 1': juegos_recomendados[0], 'Juego 2': juegos_recomendados[1], 'Juego 3': juegos_recomendados[2], 'Juego 4': juegos_recomendados[3], 'Juego 5': juegos_recomendados[4]}\n",
    "    return recomendaciones_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Juegos recomendados para el usuario Deepadeep: Juego 1': 'Starbound',\n",
       " 'Juego 2': 'Spiral Knights',\n",
       " 'Juego 3': 'Dust: An Elysian Tail',\n",
       " 'Juego 4': 'Dota 2',\n",
       " 'Juego 5': 'Realm of the Mad God'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion_usuario('Deepadeep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "    # Definir la función recomendacion_usuario\n",
    "\n",
    "\n",
    "# Cargar el modelo del archivo .pkl\n",
    "with open('user_item_model.pkl', 'rb') as archivo:\n",
    "    modelo = pickle.load(archivo)\n",
    "\n",
    "\n",
    "def recomendacion_usuario(user_id):\n",
    "    # Cargar los datos del archivo .parquet\n",
    "    new_df = pd.read_parquet('user_item_model.parquet')\n",
    "    \n",
    "    if user_id not in new_df['user_id'].unique():\n",
    "        return {'error': 'El usuario especificado no existe.'}\n",
    "\n",
    "    juegos_valorados = new_df[new_df['user_id'] == user_id]['item_name'].unique()\n",
    "    todos_los_juegos = new_df['item_name'].unique()\n",
    "    juegos_no_valorados = list(set(todos_los_juegos) - set(juegos_valorados))\n",
    "    predicciones = [modelo.predict(user_id, juego) for juego in juegos_no_valorados]\n",
    "    recomendaciones = sorted(predicciones, key=lambda x: x.est, reverse=True)[:5]\n",
    "    juegos_recomendados = [recomendacion.iid for recomendacion in recomendaciones]\n",
    "    recomendaciones_dict = {\"Juegos recomendados para el usuario\": user_id, 'Juego 1': juegos_recomendados[0], 'Juego 2': juegos_recomendados[1], 'Juego 3': juegos_recomendados[2], 'Juego 4': juegos_recomendados[3], 'Juego 5': juegos_recomendados[4]}\n",
    "    return recomendaciones_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Juegos recomendados para el usuario': 'cumme',\n",
       " 'Juego 1': 'DC Universe™ Online',\n",
       " 'Juego 2': 'Warframe',\n",
       " 'Juego 3': 'The Talos Principle',\n",
       " 'Juego 4': 'Antichamber',\n",
       " 'Juego 5': 'Borderlands 2'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion_usuario('cumme')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias por proporcionar el código de entrenamiento del modelo. Aquí está el desglose de los datos que se utilizan para entrenar el modelo:\n",
    "\n",
    "Los datos iniciales se cargan desde el archivo 'games_reviews.parquet' en el DataFrame data.\n",
    "\n",
    "Se crea una nueva columna 'rating' en data basada en las columnas 'sentiment_analysis' y 'recommend'. Esta columna 'rating' es la que se utiliza como objetivo para el entrenamiento del modelo.\n",
    "\n",
    "Estos datos procesados se guardan en un nuevo archivo 'user_item_model.parquet' y luego se cargan de nuevo en new_df.\n",
    "\n",
    "Se carga un objeto Dataset de Surprise con las columnas 'user_id', 'item_name' y 'rating' de new_df. Este Dataset se divide en un conjunto de entrenamiento y un conjunto de prueba.\n",
    "\n",
    "Se utiliza GridSearchCV para optimizar los hiperparámetros del modelo SVD. Los hiperparámetros que se optimizan son 'n_factors', 'n_epochs', 'lr_all' y 'reg_all'.\n",
    "\n",
    "Se entrena el modelo SVD con los hiperparámetros optimizados en el conjunto de entrenamiento.\n",
    "\n",
    "Por lo tanto, los datos que se utilizan para entrenar el modelo son los identificadores de usuario ('user_id'), los nombres de los juegos ('item_name') y las valoraciones ('rating') que se encuentran en el archivo 'user_item_model.parquet'.\n",
    "\n",
    "---\n",
    "\n",
    "La columna 'rating' en el DataFrame data se crea a partir de las columnas 'sentiment_analysis' y 'recommend'. Aquí está el desglose de cómo se calcula:\n",
    "\n",
    "Inicialmente, se establece la columna 'rating' en 0 para todas las filas.\n",
    "\n",
    "Luego, se asignan valores a 'rating' basándose en las columnas 'sentiment_analysis' y 'recommend' de la siguiente manera:\n",
    "\n",
    "Si 'sentiment_analysis' es 2 y 'recommend' es 1, entonces 'rating' es 5.\n",
    "Si 'sentiment_analysis' es 2 y 'recommend' es 0, entonces 'rating' es 4.\n",
    "Si 'sentiment_analysis' es 1 y 'recommend' es 1, entonces 'rating' es 3.\n",
    "Si 'sentiment_analysis' es 1 y 'recommend' es 0, entonces 'rating' es 2.\n",
    "Si 'sentiment_analysis' es 0 y 'recommend' es 1, entonces 'rating' es 1.\n",
    "Esto significa que 'rating' es una combinación de 'sentiment_analysis' y 'recommend'. 'sentiment_analysis' parece ser una medida de la positividad de la revisión del juego, mientras que 'recommend' indica si el usuario recomienda el juego o no.\n",
    "\n",
    "La columna 'rating' se utiliza luego como la variable objetivo para entrenar el modelo de recomendación.\n",
    "\n",
    "---\n",
    "La función de recomendación que proporcionaste utiliza un modelo de factorización matricial (SVD) para hacer recomendaciones. Este modelo se entrena con los identificadores de usuario ('user_id'), los nombres de los juegos ('item_name') y las valoraciones ('rating').\n",
    "\n",
    "El modelo SVD no tiene en cuenta directamente los comentarios de los usuarios ni las características del jugador. En cambio, aprende a predecir la valoración que un usuario daría a un juego basándose en las valoraciones que ese usuario ha dado a otros juegos y las valoraciones que otros usuarios han dado a ese juego.\n",
    "\n",
    "Sin embargo, la columna 'rating' que se utiliza para entrenar el modelo se calcula a partir de las columnas 'sentiment_analysis' y 'recommend', que parecen estar basadas en los comentarios de los usuarios. Por lo tanto, aunque el modelo no utiliza directamente los comentarios de los usuarios, estos influyen indirectamente en las predicciones del modelo a través de la columna 'rating'.\n",
    "\n",
    "Si quieres que el modelo tenga en cuenta directamente los comentarios de los usuarios o las características del jugador, tendrías que modificar el modelo o utilizar un enfoque de recomendación diferente que pueda incorporar este tipo de información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrir user_item_model.parquet en un dataframe\n",
    "new_df_prueba = pd.read_parquet('user_item_model.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[     'InstigatorAU', '76561198096849086',          'GamerFag',\n",
       "         'Bluegills',         'ripvision', '76561198088947777',\n",
       "         'epic_doom', '76561198049424642', '76561197970812298',\n",
       " '76561198069139035',\n",
       " ...\n",
       "      'shaman3soul3',           'waspish',             'cumme',\n",
       " '76561198015886143', '76561198072207162',           'Katidis',\n",
       " '76561198076217855',            '2ez2xl',       'matt1255555',\n",
       " 'LaLocaDeLosDulces']\n",
       "Length: 23157, dtype: string"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostrar los user_id unicos en el dataframe\n",
    "new_df_prueba['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[                   'Action',                     'Indie',\n",
       "                    'Racing',                       'RPG',\n",
       "                  'Strategy',                'Simulation',\n",
       "                 'Adventure',                    'Casual',\n",
       "               'Desconocido',                    'Sports',\n",
       "     'Massively Multiplayer',  'Animation &amp; Modeling',\n",
       "          'Video Production',                 'Utilities',\n",
       " 'Design &amp; Illustration',                 'Education',\n",
       "         'Software Training',            'Web Publishing',\n",
       "          'Audio Production']\n",
       "Length: 19, dtype: string"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostrar los user_id unicos en el dataframe\n",
    "new_df_prueba['genres'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrir archivo parquet en un dataframe\n",
    "games = pd.read_parquet('games_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>item_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>price</th>\n",
       "      <th>item_id</th>\n",
       "      <th>developer</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_url</th>\n",
       "      <th>recommend</th>\n",
       "      <th>year</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Action</td>\n",
       "      <td>Half-Life</td>\n",
       "      <td>1998</td>\n",
       "      <td>9.99</td>\n",
       "      <td>70</td>\n",
       "      <td>Valve</td>\n",
       "      <td>GamerFag</td>\n",
       "      <td>http://steamcommunity.com/id/GamerFag</td>\n",
       "      <td>True</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113207</th>\n",
       "      <td>Action</td>\n",
       "      <td>Killing Floor</td>\n",
       "      <td>2009</td>\n",
       "      <td>19.99</td>\n",
       "      <td>1250</td>\n",
       "      <td>Tripwire Interactive</td>\n",
       "      <td>GamerFag</td>\n",
       "      <td>http://steamcommunity.com/id/GamerFag</td>\n",
       "      <td>True</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117388</th>\n",
       "      <td>Action</td>\n",
       "      <td>Team Fortress 2</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.00</td>\n",
       "      <td>440</td>\n",
       "      <td>Valve</td>\n",
       "      <td>GamerFag</td>\n",
       "      <td>http://steamcommunity.com/id/GamerFag</td>\n",
       "      <td>True</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120717</th>\n",
       "      <td>Desconocido</td>\n",
       "      <td>Team Fortress 2</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.00</td>\n",
       "      <td>440</td>\n",
       "      <td>Valve</td>\n",
       "      <td>GamerFag</td>\n",
       "      <td>http://steamcommunity.com/id/GamerFag</td>\n",
       "      <td>True</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120782</th>\n",
       "      <td>Action</td>\n",
       "      <td>Half-Life 2: Episode Two</td>\n",
       "      <td>2007</td>\n",
       "      <td>7.99</td>\n",
       "      <td>420</td>\n",
       "      <td>Valve</td>\n",
       "      <td>GamerFag</td>\n",
       "      <td>http://steamcommunity.com/id/GamerFag</td>\n",
       "      <td>True</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121185</th>\n",
       "      <td>Action</td>\n",
       "      <td>Half-Life 2</td>\n",
       "      <td>2004</td>\n",
       "      <td>9.99</td>\n",
       "      <td>220</td>\n",
       "      <td>Valve</td>\n",
       "      <td>GamerFag</td>\n",
       "      <td>http://steamcommunity.com/id/GamerFag</td>\n",
       "      <td>True</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121426</th>\n",
       "      <td>Action</td>\n",
       "      <td>Half-Life 2: Episode One</td>\n",
       "      <td>2006</td>\n",
       "      <td>7.99</td>\n",
       "      <td>380</td>\n",
       "      <td>Valve</td>\n",
       "      <td>GamerFag</td>\n",
       "      <td>http://steamcommunity.com/id/GamerFag</td>\n",
       "      <td>True</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             genres                 item_name  release_date  price  item_id  \\\n",
       "4            Action                 Half-Life          1998   9.99       70   \n",
       "113207       Action             Killing Floor          2009  19.99     1250   \n",
       "117388       Action           Team Fortress 2          2007   0.00      440   \n",
       "120717  Desconocido           Team Fortress 2          2007   0.00      440   \n",
       "120782       Action  Half-Life 2: Episode Two          2007   7.99      420   \n",
       "121185       Action               Half-Life 2          2004   9.99      220   \n",
       "121426       Action  Half-Life 2: Episode One          2006   7.99      380   \n",
       "\n",
       "                   developer   user_id                               user_url  \\\n",
       "4                      Valve  GamerFag  http://steamcommunity.com/id/GamerFag   \n",
       "113207  Tripwire Interactive  GamerFag  http://steamcommunity.com/id/GamerFag   \n",
       "117388                 Valve  GamerFag  http://steamcommunity.com/id/GamerFag   \n",
       "120717                 Valve  GamerFag  http://steamcommunity.com/id/GamerFag   \n",
       "120782                 Valve  GamerFag  http://steamcommunity.com/id/GamerFag   \n",
       "121185                 Valve  GamerFag  http://steamcommunity.com/id/GamerFag   \n",
       "121426                 Valve  GamerFag  http://steamcommunity.com/id/GamerFag   \n",
       "\n",
       "        recommend  year  sentiment_analysis  \n",
       "4            True  2011                   0  \n",
       "113207       True  2010                   2  \n",
       "117388       True  2012                   2  \n",
       "120717       True  2012                   2  \n",
       "120782       True  2011                   1  \n",
       "121185       True  2011                   1  \n",
       "121426       True  2011                   2  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# buscar desarrollador Troika Games en el dataframe\n",
    "games[games['user_id'] == 'GamerFag']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 110. GiB for an array with shape (121562, 121562) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m genres_encoded \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(games[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mSeries)\u001b[38;5;241m.\u001b[39mstack())\u001b[38;5;241m.\u001b[39mgroupby(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Calcular la similitud coseno entre los juegos basada en sus géneros\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m genre_similarity \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenres_encoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Convertir la matriz de similitud en un DataFrame\u001b[39;00m\n\u001b[0;32m     11\u001b[0m genre_similarity_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(genre_similarity, index\u001b[38;5;241m=\u001b[39mgames[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, columns\u001b[38;5;241m=\u001b[39mgames[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n",
      "File \u001b[1;32mc:\\Users\\57301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\57301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1586\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1584\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1586\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_normalized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[1;32mc:\\Users\\57301\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\extmath.py:192\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    190\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    195\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    199\u001b[0m ):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 110. GiB for an array with shape (121562, 121562) and data type float64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Crear una matriz de géneros codificados\n",
    "genres_encoded = pd.get_dummies(games['genres'].apply(pd.Series).stack()).groupby(level=0).sum()\n",
    "\n",
    "# Calcular la similitud coseno entre los juegos basada en sus géneros\n",
    "genre_similarity = cosine_similarity(genres_encoded)\n",
    "\n",
    "# Convertir la matriz de similitud en un DataFrame\n",
    "genre_similarity_df = pd.DataFrame(genre_similarity, index=games['item_name'].values, columns=games['item_name'].values)\n",
    "\n",
    "# Ahora, genre_similarity_df es una matriz de similitud de género, donde cada fila y columna representa un juego,\n",
    "# y cada entrada (i, j) es la similitud de género entre los juegos i y j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Crear una matriz de géneros codificados\n",
    "genres_encoded = pd.get_dummies(games['genres'].apply(pd.Series).stack()).groupby(level=0).sum()\n",
    "\n",
    "# Aplicar PCA para reducir la dimensionalidad\n",
    "pca = PCA(n_components=min(19, genres_encoded.shape[0]))  # Ajusta este número según tus necesidades\n",
    "genres_encoded_pca = pca.fit_transform(genres_encoded)\n",
    "\n",
    "# Calcular la similitud coseno entre los juegos basada en sus géneros\n",
    "genre_similarity = cosine_similarity(genres_encoded_pca)\n",
    "\n",
    "# Convertir la matriz de similitud en un DataFrame\n",
    "genre_similarity_df = pd.DataFrame(genre_similarity, index=games['item_name'].values, columns=games['item_name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, volvemos a formar el DataFrame original con las columnas de género\n",
    "melted_games = games.melt(id_vars='item_name', value_vars=games.columns[1:])\n",
    "\n",
    "# Luego, eliminamos las filas donde el valor es 0 (es decir, el juego no pertenece a ese género)\n",
    "melted_games = melted_games[melted_games['value'] != 0]\n",
    "\n",
    "# Finalmente, contamos cuántas veces aparece cada combinación de juego y género\n",
    "game_genre_counts = melted_games.groupby(['item_name', 'variable']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_counts = games['genres'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genres\n",
       "Action                       35128\n",
       "Indie                        20755\n",
       "Desconocido                  17497\n",
       "Adventure                    13612\n",
       "RPG                           9766\n",
       "Simulation                    7216\n",
       "Strategy                      5623\n",
       "Massively Multiplayer         4828\n",
       "Casual                        4815\n",
       "Sports                        1029\n",
       "Racing                         875\n",
       "Animation &amp; Modeling       146\n",
       "Video Production               141\n",
       "Utilities                       51\n",
       "Design &amp; Illustration       33\n",
       "Web Publishing                  18\n",
       "Education                       13\n",
       "Software Training               12\n",
       "Audio Production                 4\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analiza paso a paso: Los valores de la columna genres se encontraban organizados de la siguiente forma en el archivo json \"genres\": [\"Action\", \"Casual\", \"Indie\"] para separar esas etiquetas de generos que se encuentran organizadas de esa forma use el metodo explode y separo por columnas (creando una nueva por cada genero existente en los datos dados) y en la columna genres coloco cada una de esas etiquetas de forma individual de esta forma \"genres\":\"Action\" \"genres\":\"Casual\" \"genres\":\"Indie\" lo que hice fue eliminar las columnas que me creo el explode y solo me quede con la columna genres con sus etiquetas individuales por cada genero note que hacia como un duplicado de las filas solo cambiando el genero segun las veces que el juego estaba etiquetado si tenia tres etiquetas creaba tres etiquetas duplicadas del mismo juego solo cambiando el genero este enfoque trae errores al momento de querer hacer la siguiente funcion ya que tambien me hizo perder algunos datos: def UserForGenre( genero : str ): Debe devolver el usuario que acumula más horas jugadas para el género dado y una lista de la acumulación de horas jugadas por año de lanzamiento.\n",
    "Ejemplo de retorno: {\"Usuario con más horas jugadas para Género X\" : us213ndjss09sdf, \"Horas jugadas\":[{Año: 2013, Horas: 203}, {Año: 2012, Horas: 100}, {Año: 2011, Horas: 23}]} que enfoque o solucion para separar esa columna genero resultaria mejor?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
