{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def User_For_Genre(genero):\n",
    "    # Abrimos el archivo parquet en un dataframe\n",
    "    funcion_3 = pd.read_parquet('games_items.parquet')\n",
    "\n",
    "    # Filtrar el DataFrame por el género dado\n",
    "    df_genre = funcion_3[funcion_3['genres'] == genero]\n",
    "\n",
    "    # si el dataframe esta vacio, lanzar una excepcion \n",
    "    if df_genre.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El género no existe\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    # Obtener el usuario con más horas jugadas\n",
    "    user_most_played_id = df_genre.groupby('user_id')['playtime_forever'].sum().idxmax()\n",
    "\n",
    "    # Obtener la acumulación de horas jugadas por año de lanzamiento\n",
    "    hours_per_year = get_hours_per_year(df_genre)\n",
    "\n",
    "    # Devolver los resultados en el formato especificado\n",
    "    return {\"Usuario con más horas jugadas para el género {}\".format(genero) : user_most_played_id, \"Horas jugadas\": hours_per_year}\n",
    "\n",
    "def get_hours_per_year(df_genre):\n",
    "    hours_per_year = df_genre.groupby('release_date')['playtime_forever'].sum().astype(int).reset_index()\n",
    "    hours_per_year.columns = ['Año', 'Horas']\n",
    "\n",
    "    # Cambiar el valor del año a 'desconocido' cuando es igual a 0\n",
    "    hours_per_year['Año'] = hours_per_year['Año'].apply(lambda x: 'desconocido' if x == 0 else x)\n",
    "\n",
    "    # Crear el diccionario de resultados\n",
    "    hours_per_year = hours_per_year.to_dict('records')\n",
    "\n",
    "    return hours_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Usuario con más horas jugadas para el género Design &amp; Illustration': 'BakaLunatic', 'Horas jugadas': [{'Año': 2007, 'Horas': 4}, {'Año': 2008, 'Horas': 1}, {'Año': 2012, 'Horas': 356}, {'Año': 2013, 'Horas': 359}, {'Año': 2014, 'Horas': 132}, {'Año': 2015, 'Horas': 651}, {'Año': 2016, 'Horas': 0}, {'Año': 2017, 'Horas': 0}]}\n"
     ]
    }
   ],
   "source": [
    "# llamar a la funcion\n",
    "print(User_For_Genre('Design &amp; Illustration'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN 4 - DESARROLLADOR CON MÁS JUEGOS RECOMENDADOS Y CON COMENTARIOS POSITIVOS\n",
    "def best_developer_year(year):\n",
    "\n",
    "    # Abrimos el archivo parquet en un dataframe\n",
    "    funcion_4 = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "    # Filtrar el dataframe 'games_reviews' por año, recomendaciones y comentarios positivos\n",
    "    df_filtered = funcion_4[(funcion_4['release_date'] == year) & (funcion_4['recommend'] == True) & (funcion_4['sentiment_analysis'] == 2)]\n",
    "\n",
    "    # Agrupar por desarrollador y contar las reseñas\n",
    "    developer_counts = df_filtered['developer'].value_counts()\n",
    "\n",
    "    # Ordenar los resultados y seleccionar los tres primeros\n",
    "    top_developers = developer_counts.nlargest(3)\n",
    "\n",
    "    # Crear el DataFrame de resultados\n",
    "    result = pd.DataFrame(top_developers).reset_index()\n",
    "    result.columns = ['Desarrollador', 'Cantidad']\n",
    "\n",
    "    # Convertir el DataFrame a un diccionario\n",
    "    dict_best_developer = result.to_dict('records')\n",
    "\n",
    "    return dict_best_developer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Desarrollador': 'Smartly Dressed Games', 'Cantidad': 2850}, {'Desarrollador': 'Freejam', 'Cantidad': 1020}, {'Desarrollador': 'Studio Wildcard,Instinct Games,Efecto Studios,Virtual Basement LLC', 'Cantidad': 778}]\n"
     ]
    }
   ],
   "source": [
    "# llamar a la funcion\n",
    "print(best_developer_year(2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN 4 - DESARROLLADOR CON MÁS JUEGOS RECOMENDADOS Y CON COMENTARIOS POSITIVOS\n",
    "def best_developer_year(year):\n",
    "\n",
    "    # Abrimos el archivo parquet en un dataframe\n",
    "    funcion_4 = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "\n",
    "    # Filtrar el dataframe 'games_reviews' por año, recomendaciones y comentarios positivos\n",
    "    df_filtered = funcion_4[(funcion_4['release_date'] == year) & (funcion_4['recommend'] == True) & (funcion_4['sentiment_analysis'] == 2)]\n",
    "\n",
    "    # Agrupar por desarrollador y contar las reseñas\n",
    "    developer_counts = df_filtered['developer'].value_counts()\n",
    "\n",
    "    # Ordenar los resultados y seleccionar los tres primeros\n",
    "    top_developers = developer_counts.nlargest(3)\n",
    "\n",
    "    # Crear la lista de resultados\n",
    "    list_best_developer = []\n",
    "    for i, (developer, count) in enumerate(top_developers.items(), start=1):\n",
    "        list_best_developer.append({f\"Puesto {i}\": developer})\n",
    "\n",
    "    return list_best_developer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Puesto 1': 'Oddworld Inhabitants'}, {'Puesto 2': 'Humongous Entertainment'}, {'Puesto 3': 'Interplay Inc.'}]\n"
     ]
    }
   ],
   "source": [
    "# llamar a la funcion\n",
    "print(best_developer_year(1997))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrir el archivo games_reviews.parquet\n",
    "uniondeitems = pd.read_parquet('games_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1997 1998 2006 2005 2000 2007 1996 1995 1994 2001 2004 2003 2008 1993\n",
      " 2009 2002 2010 2011 2013 2012    0 2015 2014 1992 2016 1989 1999 2017\n",
      " 1991 1990]\n"
     ]
    }
   ],
   "source": [
    "# mostrar fechas unicas \n",
    "print(uniondeitems['release_date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FUNCIÓN 5 - ANÁLISIS DE SENTIMIENTO DE RESEÑAS PARA UN DESARROLLADOR\n",
    "def desarrollador_reviews_analysis(games_reviews, desarrolladora):\n",
    "\n",
    "    # Abrimos el archivo parquet en un dataframe\n",
    "    funcion_5 = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "    # Filtrar el dataframe por el desarrollador\n",
    "    df_filtered = games_reviews[games_reviews['developer'] == desarrolladora]\n",
    "\n",
    "    # Verificar si el DataFrame filtrado está vacío y dar una excepción\n",
    "    if df_filtered.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"No hay datos para el desarrollador {}\".format(desarrolladora),\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Contar el número de reseñas con análisis de sentimiento positivo, neutral y negativo\n",
    "    sentiment_counts = df_filtered['sentiment_analysis'].value_counts()\n",
    "\n",
    "    # Crear el diccionario de resultados\n",
    "    list_reviews_analysis = {desarrolladora: {'Negativo': sentiment_counts.get(0, 0), 'Positivo': sentiment_counts.get(2, 0)}}\n",
    "\n",
    "    return list_reviews_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Valve': {'Negativo': 1446, 'Positivo': 7943}}\n"
     ]
    }
   ],
   "source": [
    "# mostrar el resultado de la funcion\n",
    "print(desarrollador_reviews_analysis(uniondeitems, 'Valve'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desarrollador_reviews_analysis(desarrolladora):\n",
    "    # Abrimos el archivo parquet en un dataframe\n",
    "    funcion_5 = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "    # Filtrar el dataframe por el desarrollador\n",
    "    df_filtered = funcion_5[funcion_5['developer'] == desarrolladora]\n",
    "\n",
    "    # Verificar si el DataFrame filtrado está vacío y dar una excepción\n",
    "    if df_filtered.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"No hay datos para el desarrollador {}\".format(desarrolladora),\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Contar el número de reseñas con análisis de sentimiento positivo y negativo\n",
    "    sentiment_counts = df_filtered['sentiment_analysis'].value_counts()\n",
    "\n",
    "    # Crear el diccionario de resultados\n",
    "    list_reviews_analysis = {desarrolladora: {'Negativo': sentiment_counts.get(0, 0), 'Positivo': sentiment_counts.get(2, 0)}}\n",
    "\n",
    "    return list_reviews_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplo = pd.read_parquet('games_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121562 entries, 0 to 121561\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   genres              121562 non-null  string \n",
      " 1   item_name           121562 non-null  object \n",
      " 2   release_date        121562 non-null  int32  \n",
      " 3   price               121562 non-null  float64\n",
      " 4   item_id             121562 non-null  int32  \n",
      " 5   developer           121562 non-null  object \n",
      " 6   user_id             121562 non-null  string \n",
      " 7   user_url            121562 non-null  string \n",
      " 8   recommend           121562 non-null  bool   \n",
      " 9   year                121562 non-null  int32  \n",
      " 10  sentiment_analysis  121562 non-null  int32  \n",
      "dtypes: bool(1), float64(1), int32(4), object(2), string(3)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "ejemplo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desarrollador_reviews_analysis(desarrolladora):\n",
    "    # Abrimos el archivo parquet en un dataframe\n",
    "    funcion_5 = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "    # Filtrar el dataframe por el desarrollador\n",
    "    df_filtered = funcion_5[funcion_5['developer'] == desarrolladora]\n",
    "\n",
    "    # Verificar si el DataFrame filtrado está vacío y dar una excepción\n",
    "    if df_filtered.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"No hay datos para el desarrollador {}\".format(desarrolladora),\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Contar el número de reseñas con análisis de sentimiento positivo y negativo\n",
    "    sentiment_counts = df_filtered['sentiment_analysis'].value_counts()\n",
    "\n",
    "    # Crear el diccionario de resultados\n",
    "    list_reviews_analysis = {desarrolladora: [{'Negative': int(sentiment_counts.get(0, 0)), 'Positive': int(sentiment_counts.get(2, 0))}]}\n",
    "\n",
    "    # Asegurarse de que el resultado es un diccionario\n",
    "    if not isinstance(list_reviews_analysis, dict):\n",
    "        list_reviews_analysis = list_reviews_analysis.to_dict()\n",
    "\n",
    "    return list_reviews_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Abrimos el archivo parquet en un dataframe\n",
    "df_gmes = pd.read_parquet('games_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stainless Games Ltd' 'Valve' 'Outerlight Ltd.' ... 'Troika Games'\n",
      " 'Neversoft' 'Malfador Machinations']\n"
     ]
    }
   ],
   "source": [
    "# mostrar lista de desarrolladores unicos\n",
    "print(df_gmes['developer'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def developer(desarrollador):\n",
    "    # Abrimos el archivo parquet en un dataframe\n",
    "    funcion_1=pd.read_parquet(\"games.parquet\")\n",
    "    # Filtrar el dataframe por el desarrollador dado\n",
    "    df_dev = funcion_1[funcion_1['developer'] == desarrollador]\n",
    "\n",
    "    # Si el dataframe está vacío, lanzar una excepción\n",
    "    if df_dev.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El desarrollador no existe\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    # Agrupar por año y contar el número total de juegos y el número de juegos gratuitos\n",
    "    juegos_por_año = df_dev.groupby('release_date').size()\n",
    "    juegos_gratis_por_año = df_dev[df_dev['price'] == 0.0].groupby('release_date').size()\n",
    "    \n",
    "    # Asegurarse de que juegos_gratis_por_año tenga la misma longitud que juegos_por_año\n",
    "    juegos_gratis_por_año = juegos_gratis_por_año.reindex(juegos_por_año.index, fill_value=0)\n",
    "    \n",
    "    # Calcular el porcentaje de juegos gratis y redondearlo al entero más cercano\n",
    "    porcentaje_gratis = ((juegos_gratis_por_año / juegos_por_año) * 100).round().astype(int)\n",
    "    \n",
    "    # Asignar nombres a las series\n",
    "    juegos_por_año.name = \"Cantidad de artículos\"\n",
    "    juegos_gratis_por_año.name = \"Contenidos Gratis\"\n",
    "    porcentaje_gratis.name = \"Porcentaje Gratis\"\n",
    "    \n",
    "    # Unir las series en un DataFrame\n",
    "    tabla = pd.concat([juegos_por_año, juegos_gratis_por_año, porcentaje_gratis], axis=1).reset_index()\n",
    "    tabla.columns = ['Año', 'Cantidad de artículos', 'Contenidos Gratis', 'Porcentaje Gratis']\n",
    "    \n",
    "    # Agregar el signo de porcentaje a 'Porcentaje Gratis'\n",
    "    tabla['Porcentaje Gratis'] = tabla['Porcentaje Gratis'].apply(lambda x: f\"{x}%\")\n",
    "    \n",
    "    # Convertir el DataFrame a un diccionario\n",
    "    dict_developer = tabla.to_dict(orient='records')\n",
    "    \n",
    "    return dict_developer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Año': 0, 'Cantidad de artículos': 2049, 'Contenidos Gratis': 331, 'Porcentaje Gratis': '16%'}, {'Año': 1970, 'Cantidad de artículos': 2, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1975, 'Cantidad de artículos': 1, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1980, 'Cantidad de artículos': 1, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1981, 'Cantidad de artículos': 3, 'Contenidos Gratis': 1, 'Porcentaje Gratis': '33%'}, {'Año': 1982, 'Cantidad de artículos': 3, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1983, 'Cantidad de artículos': 3, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1984, 'Cantidad de artículos': 2, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1985, 'Cantidad de artículos': 2, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1987, 'Cantidad de artículos': 5, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1988, 'Cantidad de artículos': 2, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1989, 'Cantidad de artículos': 3, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1990, 'Cantidad de artículos': 2, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1991, 'Cantidad de artículos': 4, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1992, 'Cantidad de artículos': 2, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1993, 'Cantidad de artículos': 9, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1994, 'Cantidad de artículos': 4, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1995, 'Cantidad de artículos': 2, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1996, 'Cantidad de artículos': 3, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1997, 'Cantidad de artículos': 3, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1998, 'Cantidad de artículos': 11, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1999, 'Cantidad de artículos': 7, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2000, 'Cantidad de artículos': 4, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2001, 'Cantidad de artículos': 10, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2002, 'Cantidad de artículos': 8, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2003, 'Cantidad de artículos': 10, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2004, 'Cantidad de artículos': 15, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2005, 'Cantidad de artículos': 10, 'Contenidos Gratis': 1, 'Porcentaje Gratis': '10%'}, {'Año': 2006, 'Cantidad de artículos': 12, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2007, 'Cantidad de artículos': 17, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2008, 'Cantidad de artículos': 17, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2009, 'Cantidad de artículos': 17, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2010, 'Cantidad de artículos': 33, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2011, 'Cantidad de artículos': 36, 'Contenidos Gratis': 2, 'Porcentaje Gratis': '6%'}, {'Año': 2012, 'Cantidad de artículos': 32, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2013, 'Cantidad de artículos': 122, 'Contenidos Gratis': 1, 'Porcentaje Gratis': '1%'}, {'Año': 2014, 'Cantidad de artículos': 98, 'Contenidos Gratis': 1, 'Porcentaje Gratis': '1%'}, {'Año': 2015, 'Cantidad de artículos': 178, 'Contenidos Gratis': 8, 'Porcentaje Gratis': '4%'}, {'Año': 2016, 'Cantidad de artículos': 244, 'Contenidos Gratis': 7, 'Porcentaje Gratis': '3%'}, {'Año': 2017, 'Cantidad de artículos': 361, 'Contenidos Gratis': 10, 'Porcentaje Gratis': '3%'}, {'Año': 2018, 'Cantidad de artículos': 4, 'Contenidos Gratis': 1, 'Porcentaje Gratis': '25%'}]\n"
     ]
    }
   ],
   "source": [
    "# llamar a la funcion\n",
    "print(developer('Dev-desconocidos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "probar =pd.read_parquet(\"games.parquet\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev-desconocidos\n"
     ]
    }
   ],
   "source": [
    "# desarrollador con mas juegos gratuitos\n",
    "print(probar[probar['price'] == 0.0]['developer'].value_counts().idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def developer(desarrollador):\n",
    "    # Abrimos el archivo parquet en un dataframe\n",
    "    funcion_1=pd.read_parquet(\"games.parquet\")\n",
    "    # Filtrar el dataframe por el desarrollador dado\n",
    "    df_dev = funcion_1[funcion_1['developer'] == desarrollador]\n",
    "\n",
    "    # Si el dataframe está vacío, lanzar una excepción\n",
    "    if df_dev.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El desarrollador no existe\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    # Agrupar por año y contar el número total de juegos y el número de juegos gratuitos\n",
    "    juegos_por_año = df_dev.groupby('release_date').size()\n",
    "    juegos_gratis_por_año = df_dev[df_dev['price'] == 0.0].groupby('release_date').size()\n",
    "    \n",
    "    # Asegurarse de que juegos_gratis_por_año tenga la misma longitud que juegos_por_año\n",
    "    juegos_gratis_por_año = juegos_gratis_por_año.reindex(juegos_por_año.index, fill_value=0)\n",
    "    \n",
    "    # Calcular el porcentaje de juegos gratis y redondearlo al entero más cercano\n",
    "    porcentaje_gratis = ((juegos_gratis_por_año / juegos_por_año) * 100).round().astype(int)\n",
    "    \n",
    "    # Asignar nombres a las series\n",
    "    juegos_por_año.name = \"Cantidad de artículos\"\n",
    "    juegos_gratis_por_año.name = \"Contenidos Gratis\"\n",
    "    porcentaje_gratis.name = \"Porcentaje Gratis\"\n",
    "    \n",
    "    # Unir las series en un DataFrame\n",
    "    tabla = pd.concat([juegos_por_año, juegos_gratis_por_año, porcentaje_gratis], axis=1).reset_index()\n",
    "    tabla.columns = ['Año', 'Cantidad de artículos', 'Contenidos Gratis', 'Porcentaje Gratis']\n",
    "    \n",
    "    # Reemplazar 0 con 'Desconocido' en la columna 'Año'\n",
    "    tabla['Año'] = tabla['Año'].replace(0, 'Desconocido')\n",
    "    \n",
    "    # Agregar el signo de porcentaje a 'Porcentaje Gratis'\n",
    "    tabla['Porcentaje Gratis'] = tabla['Porcentaje Gratis'].apply(lambda x: f\"{x}%\")\n",
    "    \n",
    "    # Convertir el DataFrame a un diccionario\n",
    "    dict_developer = tabla.to_dict(orient='records')\n",
    "    \n",
    "    return dict_developer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Año': 'Desconocido', 'Cantidad de artículos': 2049, 'Contenidos Gratis': 331, 'Porcentaje Gratis': '16%'}, {'Año': 1970, 'Cantidad de artículos': 2, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1975, 'Cantidad de artículos': 1, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1980, 'Cantidad de artículos': 1, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1981, 'Cantidad de artículos': 3, 'Contenidos Gratis': 1, 'Porcentaje Gratis': '33%'}, {'Año': 1982, 'Cantidad de artículos': 3, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1983, 'Cantidad de artículos': 3, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1984, 'Cantidad de artículos': 2, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1985, 'Cantidad de artículos': 2, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1987, 'Cantidad de artículos': 5, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1988, 'Cantidad de artículos': 2, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1989, 'Cantidad de artículos': 3, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1990, 'Cantidad de artículos': 2, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1991, 'Cantidad de artículos': 4, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1992, 'Cantidad de artículos': 2, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1993, 'Cantidad de artículos': 9, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1994, 'Cantidad de artículos': 4, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1995, 'Cantidad de artículos': 2, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1996, 'Cantidad de artículos': 3, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1997, 'Cantidad de artículos': 3, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1998, 'Cantidad de artículos': 11, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 1999, 'Cantidad de artículos': 7, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2000, 'Cantidad de artículos': 4, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2001, 'Cantidad de artículos': 10, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2002, 'Cantidad de artículos': 8, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2003, 'Cantidad de artículos': 10, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2004, 'Cantidad de artículos': 15, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2005, 'Cantidad de artículos': 10, 'Contenidos Gratis': 1, 'Porcentaje Gratis': '10%'}, {'Año': 2006, 'Cantidad de artículos': 12, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2007, 'Cantidad de artículos': 17, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2008, 'Cantidad de artículos': 17, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2009, 'Cantidad de artículos': 17, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2010, 'Cantidad de artículos': 33, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2011, 'Cantidad de artículos': 36, 'Contenidos Gratis': 2, 'Porcentaje Gratis': '6%'}, {'Año': 2012, 'Cantidad de artículos': 32, 'Contenidos Gratis': 0, 'Porcentaje Gratis': '0%'}, {'Año': 2013, 'Cantidad de artículos': 122, 'Contenidos Gratis': 1, 'Porcentaje Gratis': '1%'}, {'Año': 2014, 'Cantidad de artículos': 98, 'Contenidos Gratis': 1, 'Porcentaje Gratis': '1%'}, {'Año': 2015, 'Cantidad de artículos': 178, 'Contenidos Gratis': 8, 'Porcentaje Gratis': '4%'}, {'Año': 2016, 'Cantidad de artículos': 244, 'Contenidos Gratis': 7, 'Porcentaje Gratis': '3%'}, {'Año': 2017, 'Cantidad de artículos': 361, 'Contenidos Gratis': 10, 'Porcentaje Gratis': '3%'}, {'Año': 2018, 'Cantidad de artículos': 4, 'Contenidos Gratis': 1, 'Porcentaje Gratis': '25%'}]\n"
     ]
    }
   ],
   "source": [
    "print(developer('Dev-desconocidos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_data(user_id):\n",
    "    # Abrimos el archivo parquet en un dataframe\n",
    "    funcion_2 = pd.read_parquet('games_reviews.parquet')\n",
    "\n",
    "    # Filtrar el dataframe 'games_reviews' por el 'User_id' dado\n",
    "    df_filtered = funcion_2[funcion_2['user_id'] == user_id]\n",
    "\n",
    "    # Verificar si el dataframe filtrado está vacío\n",
    "    if df_filtered.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": f\"El usuario {user_id} no existe.\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Calcular la cantidad de dinero gastado y redondearlo a dos decimales\n",
    "    total_spent = round(df_filtered['price'].sum(), 2)\n",
    "\n",
    "    # Calcular el porcentaje de recomendación\n",
    "    total_reviews = df_filtered['recommend'].count()\n",
    "    recommended_reviews = df_filtered[df_filtered['recommend'] == True]['recommend'].count()\n",
    "    recommendation_percentage = round((recommended_reviews / total_reviews) * 100) if total_reviews > 0 else 0\n",
    "\n",
    "    # Calcular la cantidad de items\n",
    "    total_items = df_filtered['item_name'].nunique()\n",
    "\n",
    "    # Crear el diccionario de resultados\n",
    "    dict_userdata = {\n",
    "        \"Usuario\": user_id,\n",
    "        \"Dinero gastado\": f\"{total_spent} USD\",\n",
    "        \"% de recomendación\": f\"{recommendation_percentage}%\",\n",
    "        \"cantidad de artículos\": total_items\n",
    "    }\n",
    "\n",
    "    return dict_userdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Usuario': 'shaman3soul3', 'Dinero gastado': '9.99 USD', '% de recomendación': '100%', 'cantidad de artículos': 1}\n"
     ]
    }
   ],
   "source": [
    "# llamar a la funcion\n",
    "print(user_data(\"shaman3soul3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sistema de recomendación item-item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"item_similarity.pkl\", \"rb\") as archivo: \n",
    "    modelo_pickle = pickle.load(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion_juego(item_id):\n",
    "\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('item_item.parquet')\n",
    "\n",
    "    with open('item_similarity.pkl', 'rb') as f:\n",
    "            item_similarity = pickle.load(f)\n",
    "\n",
    "    # Convertir la columna 'recommend' a valores numéricos\n",
    "    data['recommend'] = data['recommend'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "    # Crear la matriz de utilidad\n",
    "    matrix = data.pivot_table(index='item_id', values=['recommend', 'sentiment_analysis'])\n",
    "\n",
    "    # Rellenar los valores faltantes con 0\n",
    "    matrix.fillna(0, inplace=True)\n",
    "\n",
    "    # Calcular la similitud del coseno\n",
    "    item_similarity = cosine_similarity(matrix)\n",
    "\n",
    "    # Convertir los resultados en un DataFrame\n",
    "    item_similarity_df = pd.DataFrame(item_similarity, index=matrix.index, columns=matrix.index)\n",
    "    \n",
    "    # Obtener los juegos similares al juego dado\n",
    "    similar_games = item_similarity_df[item_id].sort_values(ascending=False)\n",
    "\n",
    "    # Obtener los 5 juegos más similares\n",
    "    similar_games_ids = similar_games.head(6).index.tolist()[1:]  # Excluimos el primer juego porque es el mismo juego\n",
    "\n",
    "    # Crear un DataFrame con los IDs y los nombres de los juegos\n",
    "    recommended_games = pd.DataFrame(similar_games_ids, columns=['item_id'])\n",
    "    recommended_games['item_name'] = recommended_games['item_id'].apply(lambda id: data[data['item_id'] == id]['item_name'].iloc[0])\n",
    "\n",
    "    return recommended_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion_juego(item_id):\n",
    "\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('item_item.parquet')\n",
    "\n",
    "    with open('item_similarity.pkl', 'rb') as f:\n",
    "            item_similarity = pickle.load(f)\n",
    "\n",
    "    # Convertir la columna 'recommend' a valores numéricos\n",
    "    data['recommend'] = data['recommend'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "    # Crear la matriz de utilidad\n",
    "    matrix = data.pivot_table(index='item_id', values=['recommend', 'sentiment_analysis'])\n",
    "\n",
    "    # Rellenar los valores faltantes con 0\n",
    "    matrix.fillna(0, inplace=True)\n",
    "\n",
    "    # Calcular la similitud del coseno\n",
    "    item_similarity = cosine_similarity(matrix)\n",
    "\n",
    "    # Convertir los resultados en un DataFrame\n",
    "    item_similarity_df = pd.DataFrame(item_similarity, index=matrix.index, columns=matrix.index)\n",
    "    \n",
    "    # Obtener los juegos similares al juego dado\n",
    "    similar_games = item_similarity_df[item_id].sort_values(ascending=False)\n",
    "\n",
    "    # Obtener los 5 juegos más similares\n",
    "    similar_games_ids = similar_games.head(6).index.tolist()[1:]  # Excluimos el primer juego porque es el mismo juego\n",
    "\n",
    "    # Crear un diccionario con los IDs y los nombres de los juegos\n",
    "    recommended_games = {game_id: data[data['item_id'] == game_id]['item_name'].iloc[0] for game_id in similar_games_ids}\n",
    "\n",
    "    return recommended_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4560: 'Company of Heroes - Legacy Edition',\n",
       " 222880: 'Insurgency',\n",
       " 206500: 'AirMech Strike',\n",
       " 6060: 'Star Wars: Battlefront 2 (Classic, 2005)',\n",
       " 22380: 'Fallout: New Vegas'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prueba la función con un item_id\n",
    "recomendacion_juego(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion_juego(item_id):\n",
    "\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('item_item.parquet')\n",
    "\n",
    "    # Si el dataframe está vacío, lanzar una excepción\n",
    "    if data.empty:\n",
    "        raise ValueError(\"El DataFrame está vacío\")\n",
    "\n",
    "    with open('item_similarity.pkl', 'rb') as f:\n",
    "            item_similarity = pickle.load(f)\n",
    "\n",
    "    # Convertir la columna 'recommend' a valores numéricos\n",
    "    data['recommend'] = data['recommend'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "    # Crear la matriz de utilidad\n",
    "    matrix = data.pivot_table(index='item_id', values=['recommend', 'sentiment_analysis'])\n",
    "\n",
    "    # Rellenar los valores faltantes con 0\n",
    "    matrix.fillna(0, inplace=True)\n",
    "\n",
    "    # Calcular la similitud del coseno\n",
    "    item_similarity = cosine_similarity(matrix)\n",
    "\n",
    "    # Convertir los resultados en un DataFrame\n",
    "    item_similarity_df = pd.DataFrame(item_similarity, index=matrix.index, columns=matrix.index)\n",
    "    \n",
    "    # Obtener los juegos similares al juego dado\n",
    "    similar_games = item_similarity_df[item_id].sort_values(ascending=False)\n",
    "\n",
    "    # Obtener los 5 juegos más similares\n",
    "    similar_games_ids = similar_games.head(6).index.tolist()[1:]  # Excluimos el primer juego porque es el mismo juego\n",
    "\n",
    "    # Crear un diccionario con los IDs y los nombres de los juegos\n",
    "    recommended_games = {game_id: data[data['item_id'] == game_id]['item_name'].iloc[0] for game_id in similar_games_ids}\n",
    "\n",
    "    return recommended_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba la función con un item_id\n",
    "recomendacion_juego(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion_juego(item_id):\n",
    "\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('item_item.parquet')\n",
    "\n",
    "    # Si el dataframe está vacío, lanzar una excepción\n",
    "    if data.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El DataFrame está vacío\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    with open('item_similarity.pkl', 'rb') as f:\n",
    "            item_similarity = pickle.load(f)\n",
    "\n",
    "    # Convertir la columna 'recommend' a valores numéricos\n",
    "    data['recommend'] = data['recommend'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "    # Crear la matriz de utilidad\n",
    "    matrix = data.pivot_table(index='item_id', values=['recommend', 'sentiment_analysis'])\n",
    "\n",
    "    # Rellenar los valores faltantes con 0\n",
    "    matrix.fillna(0, inplace=True)\n",
    "\n",
    "    # Calcular la similitud del coseno\n",
    "    item_similarity = cosine_similarity(matrix)\n",
    "\n",
    "    # Convertir los resultados en un DataFrame\n",
    "    item_similarity_df = pd.DataFrame(item_similarity, index=matrix.index, columns=matrix.index)\n",
    "    \n",
    "    # Obtener los juegos similares al juego dado\n",
    "    similar_games = item_similarity_df[item_id].sort_values(ascending=False)\n",
    "\n",
    "    # Obtener los 5 juegos más similares\n",
    "    similar_games_ids = similar_games.head(6).index.tolist()[1:]  # Excluimos el primer juego porque es el mismo juego\n",
    "\n",
    "    # Crear un diccionario con los IDs y los nombres de los juegos\n",
    "    recommended_games = {game_id: data[data['item_id'] == game_id]['item_name'].iloc[0] for game_id in similar_games_ids}\n",
    "\n",
    "    return recommended_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba la función con un item_id\n",
    "recomendacion_juego(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion_juego(item_id):\n",
    "\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('item_item.parquet')\n",
    "\n",
    "    # Si el dataframe está vacío, devolver un mensaje de error\n",
    "    if data.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El DataFrame está vacío\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Si el item_id no existe en el DataFrame, devolver un mensaje de error\n",
    "    if item_id not in data['item_id'].values:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El item_id proporcionado no existe\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    with open('item_similarity.pkl', 'rb') as f:\n",
    "            item_similarity = pickle.load(f)\n",
    "\n",
    "    # Convertir la columna 'recommend' a valores numéricos\n",
    "    data['recommend'] = data['recommend'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "    # Crear la matriz de utilidad\n",
    "    matrix = data.pivot_table(index='item_id', values=['recommend', 'sentiment_analysis'])\n",
    "\n",
    "    # Rellenar los valores faltantes con 0\n",
    "    matrix.fillna(0, inplace=True)\n",
    "\n",
    "    # Calcular la similitud del coseno\n",
    "    item_similarity = cosine_similarity(matrix)\n",
    "\n",
    "    # Convertir los resultados en un DataFrame\n",
    "    item_similarity_df = pd.DataFrame(item_similarity, index=matrix.index, columns=matrix.index)\n",
    "    \n",
    "    # Obtener los juegos similares al juego dado\n",
    "    similar_games = item_similarity_df[item_id].sort_values(ascending=False)\n",
    "\n",
    "    # Obtener los 5 juegos más similares\n",
    "    similar_games_ids = similar_games.head(6).index.tolist()[1:]  # Excluimos el primer juego porque es el mismo juego\n",
    "\n",
    "    # Crear un diccionario con los IDs y los nombres de los juegos\n",
    "    recommended_games = {game_id: data[data['item_id'] == game_id]['item_name'].iloc[0] for game_id in similar_games_ids}\n",
    "\n",
    "    return recommended_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{265630: 'Fistful of Frags',\n",
       " 42910: 'Magicka',\n",
       " 10180: 'Call of Duty®: Modern Warfare® 2',\n",
       " 212800: 'Super Crate Box',\n",
       " 550: 'Left 4 Dead 2'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prueba la función con un item_id\n",
    "recomendacion_juego(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion_juego(item_id):\n",
    "\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('item_item.parquet')\n",
    "\n",
    "    # Si el dataframe está vacío, devolver un mensaje de error\n",
    "    if data.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El DataFrame está vacío\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Si el item_id no existe en el DataFrame, devolver un mensaje de error\n",
    "    if item_id not in data['item_id'].values:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El item_id proporcionado no existe\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    with open('item_similarity.pkl', 'rb') as f:\n",
    "            item_similarity = pickle.load(f)\n",
    "\n",
    "    # Convertir la columna 'recommend' a valores numéricos\n",
    "    data['recommend'] = data['recommend'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "    # Crear la matriz de utilidad\n",
    "    matrix = data.pivot_table(index='item_id', values=['recommend', 'sentiment_analysis'])\n",
    "\n",
    "    # Rellenar los valores faltantes con 0\n",
    "    matrix.fillna(0, inplace=True)\n",
    "\n",
    "    # Calcular la similitud del coseno\n",
    "    item_similarity = cosine_similarity(matrix)\n",
    "\n",
    "    # Convertir los resultados en un DataFrame\n",
    "    item_similarity_df = pd.DataFrame(item_similarity, index=matrix.index, columns=matrix.index)\n",
    "    \n",
    "    # Obtener los juegos similares al juego dado\n",
    "    similar_games = item_similarity_df[item_id].sort_values(ascending=False)\n",
    "\n",
    "    # Obtener los 5 juegos más similares\n",
    "    similar_games_ids = similar_games.head(6).index.tolist()[1:]  # Excluimos el primer juego porque es el mismo juego\n",
    "\n",
    "    # Crear un diccionario con los IDs y los nombres de los juegos\n",
    "    recommended_games = {game_id: data[data['item_id'] == game_id]['item_name'].iloc[0] for game_id in similar_games_ids}\n",
    "\n",
    "    return { \"Juegos similares al id ingresado\": recommended_games}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Juegos similares al id ingresado': {4560: 'Company of Heroes - Legacy Edition',\n",
       "  222880: 'Insurgency',\n",
       "  206500: 'AirMech Strike',\n",
       "  6060: 'Star Wars: Battlefront 2 (Classic, 2005)',\n",
       "  22380: 'Fallout: New Vegas'}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prueba la función con un item_id\n",
    "recomendacion_juego(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Abrir el archivo parquet en un DataFrame\n",
    "data_prueba = pd.read_parquet('item_item.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121562 entries, 0 to 121561\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   item_id             121562 non-null  int32 \n",
      " 1   recommend           121562 non-null  int64 \n",
      " 2   sentiment_analysis  121562 non-null  int32 \n",
      " 3   item_name           121562 non-null  object\n",
      "dtypes: int32(2), int64(1), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data_prueba.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SISTEMA DE RECOMENDACIÓN - ITEM-ITEM\n",
    "def recomendacion_juego(item_id):\n",
    "\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('item_item.parquet')\n",
    "\n",
    "    # Si el dataframe está vacío, devolver un mensaje de error\n",
    "    if data.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El DataFrame está vacío\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Si el item_id no existe en el DataFrame, devolver un mensaje de error\n",
    "    if item_id not in data['item_id'].values:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El item_id proporcionado no existe\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # with open('item_similarity.pkl', 'rb') as f:\n",
    "    #         item_similarity = pickle.load(f)\n",
    "\n",
    "    # Convertir la columna 'recommend' a valores numéricos\n",
    "    data['recommend'] = data['recommend'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "    # Crear la matriz de utilidad\n",
    "    matrix = data.pivot_table(index='item_id', values=['recommend', 'sentiment_analysis'])\n",
    "\n",
    "    # Rellenar los valores faltantes con 0\n",
    "    matrix.fillna(0, inplace=True)\n",
    "\n",
    "    # Calcular la similitud del coseno\n",
    "    item_similarity = cosine_similarity(matrix)\n",
    "\n",
    "    # Convertir los resultados en un DataFrame\n",
    "    item_similarity_df = pd.DataFrame(item_similarity, index=matrix.index, columns=matrix.index)\n",
    "    \n",
    "    # Obtener los juegos similares al juego dado\n",
    "    similar_games = item_similarity_df[item_id].sort_values(ascending=False)\n",
    "\n",
    "    # Obtener los 5 juegos más similares\n",
    "    similar_games_ids = similar_games.head(6).index.tolist()[1:]  # Excluimos el primer juego porque es el mismo juego\n",
    "\n",
    "    # Crear un diccionario con los IDs y los nombres de los juegos\n",
    "    recommended_games = {game_id: data[data['item_id'] == game_id]['item_name'].iloc[0] for game_id in similar_games_ids}\n",
    "\n",
    "    return { \"Juegos similares al id ingresado\": recommended_games}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Juegos similares al id ingresado': {4560: 'Company of Heroes - Legacy Edition',\n",
       "  222880: 'Insurgency',\n",
       "  206500: 'AirMech Strike',\n",
       "  6060: 'Star Wars: Battlefront 2 (Classic, 2005)',\n",
       "  22380: 'Fallout: New Vegas'}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prueba la función con un item_id\n",
    "recomendacion_juego(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion_juego(item_id):\n",
    "\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('item_item.parquet')\n",
    "\n",
    "    # Si el dataframe está vacío, devolver un mensaje de error\n",
    "    if data.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El DataFrame está vacío\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Si el item_id no existe en el DataFrame, devolver un mensaje de error\n",
    "    if item_id not in data['item_id'].values:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El item_id proporcionado no existe\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # with open('item_similarity.pkl', 'rb') as f:\n",
    "    #         item_similarity = pickle.load(f)\n",
    "\n",
    "    # Convertir la columna 'recommend' a valores numéricos\n",
    "    data['recommend'] = data['recommend'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "    # Crear la matriz de utilidad\n",
    "    matrix = data.pivot_table(index='item_id', values=['recommend', 'sentiment_analysis'])\n",
    "\n",
    "    # Rellenar los valores faltantes con 0\n",
    "    matrix.fillna(0, inplace=True)\n",
    "\n",
    "    # Calcular la similitud del coseno\n",
    "    item_similarity = cosine_similarity(matrix)\n",
    "\n",
    "    # Convertir los resultados en un DataFrame\n",
    "    item_similarity_df = pd.DataFrame(item_similarity, index=matrix.index, columns=matrix.index)\n",
    "    \n",
    "    # Obtener los juegos similares al juego dado\n",
    "    similar_games = item_similarity_df[item_id].sort_values(ascending=False)\n",
    "\n",
    "    # Obtener los 5 juegos más similares\n",
    "    similar_games_ids = similar_games.head(6).index.tolist()[1:]  # Excluimos el primer juego porque es el mismo juego\n",
    "\n",
    "    # Crear un diccionario con los IDs y los nombres de los juegos\n",
    "    recommended_games = {game_id: data[data['item_id'] == game_id]['item_name'].iloc[0] for game_id in similar_games_ids}\n",
    "\n",
    "    return { \"Juegos similares al id ingresado\": recommended_games}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>recommend</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "      <th>item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Half-Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Half-Life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  recommend  sentiment_analysis             item_name\n",
       "0   282010          1                   1  Carmageddon Max Pack\n",
       "1   282010          1                   1  Carmageddon Max Pack\n",
       "2   282010          1                   1  Carmageddon Max Pack\n",
       "3       70          1                   0             Half-Life\n",
       "4       70          1                   0             Half-Life"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prueba.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrir un archivo parquet\n",
    "data_prueba = pd.read_parquet('item_item.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>recommend</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "      <th>item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Half-Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Half-Life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  recommend  sentiment_analysis             item_name\n",
       "0   282010          1                   1  Carmageddon Max Pack\n",
       "1   282010          1                   1  Carmageddon Max Pack\n",
       "2   282010          1                   1  Carmageddon Max Pack\n",
       "3       70          1                   0             Half-Life\n",
       "4       70          1                   0             Half-Life"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prueba.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Convertir la columna 'recommend' a valores numéricos\n",
    "data_prueba['recommend'] = data_prueba['recommend'].apply(lambda x: 1 if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>recommend</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "      <th>item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Half-Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Half-Life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  recommend  sentiment_analysis             item_name\n",
       "0   282010          1                   1  Carmageddon Max Pack\n",
       "1   282010          1                   1  Carmageddon Max Pack\n",
       "2   282010          1                   1  Carmageddon Max Pack\n",
       "3       70          1                   0             Half-Life\n",
       "4       70          1                   0             Half-Life"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prueba.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valore unicos de la columna sentiment_analysis\n",
    "data_prueba['sentiment_analysis'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SISTEMA DE RECOMENDACIÓN - ITEM-ITEM\n",
    "def recomendacion_juego(item_id):\n",
    "    # Abrir el archivo parquet en un DataFrame\n",
    "    data = pd.read_parquet('item_item.parquet')\n",
    "\n",
    "    # Si el dataframe está vacío, devolver un mensaje de error\n",
    "    if data.empty:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El DataFrame está vacío\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Si el item_id no existe en el DataFrame, devolver un mensaje de error\n",
    "    if item_id not in data['item_id'].values:\n",
    "        return {\n",
    "            \"detail\": [\n",
    "                {\n",
    "                    \"loc\": [\"string\", 0],\n",
    "                    \"msg\": \"El item_id proporcionado no existe\",\n",
    "                    \"type\": \"value_error\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    # Esta excepción carga la matriz de similitud de items_similarity que contiene la operación de calcular la similitud del coseno \n",
    "    try:\n",
    "        with open('item_similarity.pkl', 'rb') as f:\n",
    "            item_similarity_df = pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error al cargar el archivo: {e}\")\n",
    "        \n",
    "        # Ajuste manual de valores en la columna 'sentiment_analysis'\n",
    "        data['sentiment_analysis'] = data['sentiment_analysis'].apply(lambda x: 1 if x == 2 else 0)\n",
    "\n",
    "\n",
    "        # Convertir la columna 'recommend' a valores numéricos\n",
    "        data['recommend'] = data['recommend'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "        # Crear la matriz de utilidad\n",
    "        matrix = data.pivot_table(index='item_id', values=['recommend', 'sentiment_analysis'])\n",
    "\n",
    "        # Rellenar los valores faltantes con 0\n",
    "        matrix.fillna(0, inplace=True)\n",
    "\n",
    "        # Calcular la similitud del coseno\n",
    "        item_similarity = cosine_similarity(matrix)\n",
    "\n",
    "        # Convertir los resultados en un DataFrame\n",
    "        item_similarity_df = pd.DataFrame(item_similarity, index=matrix.index, columns=matrix.index)\n",
    "    \n",
    "    # Obtener los juegos similares al juego dado\n",
    "    similar_games = item_similarity_df[item_id].sort_values(ascending=False)\n",
    "\n",
    "    # Obtener los 5 juegos más similares\n",
    "    similar_games_ids = similar_games.head(6).index.tolist()[1:]  # Excluimos el primer juego porque es el mismo juego\n",
    "\n",
    "    # Crear un diccionario con los IDs y los nombres de los juegos\n",
    "    recommended_games = {game_id: data[data['item_id'] == game_id]['item_name'].iloc[0] for game_id in similar_games_ids}\n",
    "\n",
    "    return { \"Juegos similares al id ingresado\": recommended_games}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('item_item.parquet')\n",
    "# Ajuste manual de valores en la columna 'sentiment_analysis'\n",
    "data['sentiment_analysis'] = data['sentiment_analysis'].apply(lambda x: 1 if x == 2 else 0)\n",
    "\n",
    " # Convertir la columna 'recommend' a valores numéricos\n",
    "data['recommend'] = data['recommend'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "# Crear la matriz de utilidad\n",
    "matrix = data.pivot_table(index='item_id', values=['recommend', 'sentiment_analysis'])\n",
    "\n",
    "# Rellenar los valores faltantes con 0\n",
    "matrix.fillna(0, inplace=True)\n",
    "\n",
    "# Calcular la similitud del coseno\n",
    "item_similarity = cosine_similarity(matrix)\n",
    "\n",
    "# Convertir los resultados en un DataFrame\n",
    "item_similarity_df = pd.DataFrame(item_similarity, index=matrix.index, columns=matrix.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>30</th>\n",
       "      <th>40</th>\n",
       "      <th>50</th>\n",
       "      <th>60</th>\n",
       "      <th>70</th>\n",
       "      <th>80</th>\n",
       "      <th>130</th>\n",
       "      <th>220</th>\n",
       "      <th>...</th>\n",
       "      <th>512540</th>\n",
       "      <th>512630</th>\n",
       "      <th>514520</th>\n",
       "      <th>516040</th>\n",
       "      <th>520550</th>\n",
       "      <th>521340</th>\n",
       "      <th>521430</th>\n",
       "      <th>521570</th>\n",
       "      <th>521990</th>\n",
       "      <th>527340</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982298</td>\n",
       "      <td>0.972275</td>\n",
       "      <td>0.972275</td>\n",
       "      <td>0.929434</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.999254</td>\n",
       "      <td>0.999543</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.999700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974205</td>\n",
       "      <td>0.522154</td>\n",
       "      <td>0.972275</td>\n",
       "      <td>0.972275</td>\n",
       "      <td>0.972275</td>\n",
       "      <td>0.972275</td>\n",
       "      <td>0.972275</td>\n",
       "      <td>0.852851</td>\n",
       "      <td>0.972275</td>\n",
       "      <td>0.852851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.982298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998868</td>\n",
       "      <td>0.998868</td>\n",
       "      <td>0.982102</td>\n",
       "      <td>0.980581</td>\n",
       "      <td>0.988799</td>\n",
       "      <td>0.976187</td>\n",
       "      <td>0.980581</td>\n",
       "      <td>0.986594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914687</td>\n",
       "      <td>0.672673</td>\n",
       "      <td>0.998868</td>\n",
       "      <td>0.998868</td>\n",
       "      <td>0.998868</td>\n",
       "      <td>0.998868</td>\n",
       "      <td>0.998868</td>\n",
       "      <td>0.739940</td>\n",
       "      <td>0.998868</td>\n",
       "      <td>0.739940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.972275</td>\n",
       "      <td>0.998868</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>0.970143</td>\n",
       "      <td>0.980581</td>\n",
       "      <td>0.964764</td>\n",
       "      <td>0.970143</td>\n",
       "      <td>0.977715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894427</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.972275</td>\n",
       "      <td>0.998868</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>0.970143</td>\n",
       "      <td>0.980581</td>\n",
       "      <td>0.964764</td>\n",
       "      <td>0.970143</td>\n",
       "      <td>0.977715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894427</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.929434</td>\n",
       "      <td>0.982102</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926092</td>\n",
       "      <td>0.942990</td>\n",
       "      <td>0.917857</td>\n",
       "      <td>0.926092</td>\n",
       "      <td>0.938198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822192</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id    10        20        30        40        50        60        70      \\\n",
       "item_id                                                                         \n",
       "10       1.000000  0.982298  0.972275  0.972275  0.929434  0.999960  0.999254   \n",
       "20       0.982298  1.000000  0.998868  0.998868  0.982102  0.980581  0.988799   \n",
       "30       0.972275  0.998868  1.000000  1.000000  0.989949  0.970143  0.980581   \n",
       "40       0.972275  0.998868  1.000000  1.000000  0.989949  0.970143  0.980581   \n",
       "50       0.929434  0.982102  0.989949  0.989949  1.000000  0.926092  0.942990   \n",
       "\n",
       "item_id    80        130       220     ...    512540    512630    514520  \\\n",
       "item_id                                ...                                 \n",
       "10       0.999543  0.999960  0.999700  ...  0.974205  0.522154  0.972275   \n",
       "20       0.976187  0.980581  0.986594  ...  0.914687  0.672673  0.998868   \n",
       "30       0.964764  0.970143  0.977715  ...  0.894427  0.707107  1.000000   \n",
       "40       0.964764  0.970143  0.977715  ...  0.894427  0.707107  1.000000   \n",
       "50       0.917857  0.926092  0.938198  ...  0.822192  0.800000  0.989949   \n",
       "\n",
       "item_id    516040    520550    521340    521430    521570    521990    527340  \n",
       "item_id                                                                        \n",
       "10       0.972275  0.972275  0.972275  0.972275  0.852851  0.972275  0.852851  \n",
       "20       0.998868  0.998868  0.998868  0.998868  0.739940  0.998868  0.739940  \n",
       "30       1.000000  1.000000  1.000000  1.000000  0.707107  1.000000  0.707107  \n",
       "40       1.000000  1.000000  1.000000  1.000000  0.707107  1.000000  0.707107  \n",
       "50       0.989949  0.989949  0.989949  0.989949  0.600000  0.989949  0.600000  \n",
       "\n",
       "[5 rows x 3157 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_similarity_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir el dataframe item_similarity_df a un archivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir los valores que son iguales a 2 de la columna sentiment_analysis a 1 y los valores 1 a 0\n",
    "data['sentiment_analysis'] = data['sentiment_analysis'].apply(lambda x: 1 if x == 2 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>recommend</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "      <th>item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Half-Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Half-Life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  recommend  sentiment_analysis             item_name\n",
       "0   282010          1                   0  Carmageddon Max Pack\n",
       "1   282010          1                   0  Carmageddon Max Pack\n",
       "2   282010          1                   0  Carmageddon Max Pack\n",
       "3       70          1                   0             Half-Life\n",
       "4       70          1                   0             Half-Life"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('item_item.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>recommend</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "      <th>item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Half-Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Half-Life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  recommend  sentiment_analysis             item_name\n",
       "0   282010          1                   1  Carmageddon Max Pack\n",
       "1   282010          1                   1  Carmageddon Max Pack\n",
       "2   282010          1                   1  Carmageddon Max Pack\n",
       "3       70          1                   0             Half-Life\n",
       "4       70          1                   0             Half-Life"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplaza los valores 2 por 1 y los valores 1 por 0\n",
    "df['sentiment_analysis'] = df['sentiment_analysis'].replace({2: 1, 1: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>recommend</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "      <th>item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Carmageddon Max Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Half-Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Half-Life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  recommend  sentiment_analysis             item_name\n",
       "0   282010          1                   0  Carmageddon Max Pack\n",
       "1   282010          1                   0  Carmageddon Max Pack\n",
       "2   282010          1                   0  Carmageddon Max Pack\n",
       "3       70          1                   0             Half-Life\n",
       "4       70          1                   0             Half-Life"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valores unicos de la column sentiment_analysis\n",
    "df['sentiment_analysis'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_data(user_id):\n",
    "    \"\"\"\n",
    "    Esta función toma como entrada el ID de un usuario y devuelve un diccionario que contiene información sobre el comportamiento de compra y recomendación del usuario. \n",
    "    La información incluye la cantidad total de dinero gastado por el usuario, el porcentaje de juegos que el usuario ha recomendado y la cantidad de artículos únicos que el usuario ha comprado.\n",
    "    \n",
    "    Parámetros:\n",
    "    user_id (str): El ID del usuario.\n",
    "    \n",
    "    Devuelve:\n",
    "    dict_userdata (dict): Un diccionario que contiene información sobre el comportamiento de compra y recomendación del usuario.\n",
    "    \"\"\"\n",
    "    # El resto del código de la función va aquí..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuevo enfoque **ETL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrir el archivo parquet\n",
    "data = pd.read_parquet('games_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[282010     70   2400 ...     30  13230     80]\n"
     ]
    }
   ],
   "source": [
    "print(data['item_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar frecuencia de los valores de la columna user_id en un archivo csv\n",
    "data['user_id'].value_counts().to_csv('user_id.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "Cleze                40\n",
      "snakedog             39\n",
      "76561198052479552    39\n",
      "76561198095839864    35\n",
      "76561198060201321    34\n",
      "                     ..\n",
      "stefchygamer          1\n",
      "Bukky                 1\n",
      "L_iS_De_Best          1\n",
      "FullTimeSilver3       1\n",
      "LaLocaDeLosDulces     1\n",
      "Name: count, Length: 23157, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "# frecuencia de los generos\n",
    "print(data['user_id'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
